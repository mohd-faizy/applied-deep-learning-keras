{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"  background: linear-gradient(145deg, #0f172a, #1e293b);  border: 4px solid transparent;  border-radius: 14px;  padding: 18px 22px;  margin: 12px 0;  font-size: 26px;  font-weight: 600;  color: #f8fafc;  box-shadow: 0 6px 14px rgba(0,0,0,0.25);  background-clip: padding-box;  position: relative;\">  <div style=\"    position: absolute;    inset: 0;    padding: 4px;    border-radius: 14px;    background: linear-gradient(90deg, #06b6d4, #3b82f6, #8b5cf6);    -webkit-mask:       linear-gradient(#fff 0 0) content-box,       linear-gradient(#fff 0 0);    -webkit-mask-composite: xor;    mask-composite: exclude;    pointer-events: none;  \"></div>    <b>Convolutions: Image Modeling with Keras</b>    <br/>  <span style=\"color:#9ca3af; font-size: 18px; font-weight: 400;\">(From Mathematical Foundations to Keras Implementation)</span></div>\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "1. [Using Correlations in Images](#section-1)\n",
        "2. [What is a Convolution? (1D Implementation)](#section-2)\n",
        "3. [Two-Dimensional Convolution (Manual Implementation)](#section-3)\n",
        "4. [Implementing Convolutions in Keras](#section-4)\n",
        "5. [Fitting a CNN](#section-5)\n",
        "6. [Tweaking Convolutions: Padding, Strides, and Dilation](#section-6)\n",
        "7. [Calculating Output Sizes](#section-7)\n",
        "8. [Conclusion](#section-8)\n",
        "\n",
        "---\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 1. Using Correlations in Images</span><br>\n",
        "\n",
        "### The Nature of Images\n",
        "Natural images are not random collections of pixels; they contain **spatial correlations**. This means that pixels close to each other often share similar values or form specific structures.\n",
        "\n",
        "*   **Contours and Edges**: Pixels along a line or curve are correlated.\n",
        "*   **Textures**: Repeating patterns in a specific region.\n",
        "\n",
        "### Biological Inspiration\n",
        "Convolutional Neural Networks (CNNs) draw inspiration from biology, specifically the visual cortex.\n",
        "*   Neurons in the visual cortex respond to specific stimuli in a restricted region of the visual field known as the **receptive field**.\n",
        "*   Some neurons fire only when they see a vertical line; others fire for horizontal lines or specific colors.\n",
        "*   By stacking these layers, the brain processes complex visual information.\n",
        "\n",
        "<div style=\"background: #e0f2fe; border-left: 16px solid #0284c7; padding: 14px 18px; border-radius: 8px; font-size: 18px; color: #075985;\"> ðŸ’¡ <b>Tip:</b> In Deep Learning, we use <b>Convolutions</b> to mathematically model these receptive fields and exploit spatial correlations. </div>\n",
        "\n",
        "---\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 2. What is a Convolution? (1D Implementation)</span><br>\n",
        "\n",
        "A convolution is a mathematical operation where a **kernel** (or filter) slides over an input array. At each step, we perform element-wise multiplication and sum the results.\n",
        "\n",
        "### 1D Convolution Logic\n",
        "1.  Take a small kernel (e.g., size 2).\n",
        "2.  Overlay it on the beginning of the input array.\n",
        "3.  Multiply overlapping values and sum them.\n",
        "4.  Slide the kernel one step to the right and repeat.\n",
        "\n",
        "### Original Code Implementation\n",
        "Below is the manual implementation of a 1D convolution using NumPy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the input array (simulating a 1D signal or image row)\n",
        "array = np.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n",
        "\n",
        "# Define the kernel (edge detector)\n",
        "kernel = np.array([-1, 1])\n",
        "\n",
        "# Initialize the result array (convolution output)\n",
        "# Note: The output size is typically len(array) - len(kernel) + 1\n",
        "conv = np.zeros(9)  # 10 - 2 + 1 = 9\n",
        "\n",
        "# Manual calculation of the first few steps\n",
        "conv[0] = (kernel * array[0:2]).sum()\n",
        "conv[1] = (kernel * array[1:3]).sum()\n",
        "conv[2] = (kernel * array[2:4]).sum()\n",
        "\n",
        "# Automating with a loop\n",
        "for ii in range(8):\n",
        "    conv[ii] = (kernel * array[ii:ii+2]).sum()\n",
        "\n",
        "print(\"Resulting Convolution Array:\")\n",
        "print(conv)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Enhanced Code Implementation\n",
        "Here is a more robust version that calculates the range dynamically based on array sizes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def convolve_1d(array, kernel):\n",
        "    # Calculate output size\n",
        "    output_len = len(array) - len(kernel) + 1\n",
        "    conv = np.zeros(output_len)\n",
        "    \n",
        "    # Slide the kernel\n",
        "    for ii in range(output_len):\n",
        "        # Extract the window\n",
        "        window = array[ii : ii + len(kernel)]\n",
        "        # Multiply and sum\n",
        "        conv[ii] = (window * kernel).sum()\n",
        "        \n",
        "    return conv\n",
        "\n",
        "# Test Data\n",
        "array_data = np.array([0, 0, 1, 1, 0, 0, 1, 1, 0, 0])\n",
        "kernel_data = np.array([-1, 1])\n",
        "\n",
        "result = convolve_1d(array_data, kernel_data)\n",
        "print(f\"Input:  {array_data}\")\n",
        "print(f\"Kernel: {kernel_data}\")\n",
        "print(f\"Output: {result}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "**Interpretation**: The kernel `[-1, 1]` acts as an edge detector. It outputs non-zero values where the input transitions from 0 to 1 (positive edge) or 1 to 0 (negative edge).\n",
        "\n",
        "---\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 3. Two-Dimensional Convolution (Manual Implementation)</span><br>\n",
        "\n",
        "Images are 2D grids of pixels. To process them, we slide a 2D kernel over the image in both horizontal and vertical directions.\n",
        "\n",
        "### The Mechanism\n",
        "1.  Define a 2D Kernel (e.g., 3x3 or 2x2).\n",
        "2.  Place the kernel at the top-left corner of the image.\n",
        "3.  Multiply the kernel values by the underlying image pixel values.\n",
        "4.  Sum the products to get a single output pixel.\n",
        "5.  Slide the kernel horizontally, then vertically.\n",
        "\n",
        "### Manual 2D Convolution Code\n",
        "The following code demonstrates how to implement this using nested loops.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create a dummy 2D image (28x28) with random values for demonstration\n",
        "image = np.random.rand(28, 28)\n",
        "\n",
        "# Define a 2D kernel (Edge detection filter)\n",
        "kernel = np.array([[-1, 1],\n",
        "                   [-1, 1]])\n",
        "\n",
        "# Initialize output array\n",
        "# Output dimension = Input - Kernel + 1\n",
        "# 28 - 2 + 1 = 27\n",
        "conv = np.zeros((27, 27))\n",
        "\n",
        "# Iterate over rows\n",
        "for ii in range(27):\n",
        "    # Iterate over columns\n",
        "    for jj in range(27):\n",
        "        # Extract the window matching the kernel size (2x2)\n",
        "        window = image[ii:ii+2, jj:jj+2]\n",
        "        \n",
        "        # Perform convolution operation\n",
        "        conv[ii, jj] = np.sum(window * kernel)\n",
        "\n",
        "print(f\"Original Image Shape: {image.shape}\")\n",
        "print(f\"Kernel Shape: {kernel.shape}\")\n",
        "print(f\"Convolved Output Shape: {conv.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<div style=\"background: #e0f2fe; border-left: 16px solid #0284c7; padding: 14px 18px; border-radius: 8px; font-size: 18px; color: #075985;\"> ðŸ’¡ <b>Tip:</b> While nested loops help us understand the logic, they are computationally slow. Libraries like Keras and TensorFlow use highly optimized matrix operations to perform these calculations instantly. </div>\n",
        "\n",
        "---\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 4. Implementing Convolutions in Keras</span><br>\n",
        "\n",
        "Keras provides the `Conv2D` layer to handle image convolutions efficiently.\n",
        "\n",
        "### The `Conv2D` Layer\n",
        "The core arguments for a convolution layer are:\n",
        "1.  **Filters**: The number of kernels to learn (e.g., 10).\n",
        "2.  **Kernel Size**: The dimensions of the kernel (e.g., 3 for a 3x3 kernel).\n",
        "3.  **Activation**: The activation function (e.g., 'relu').\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Conv2D\n",
        "\n",
        "# Example instantiation (not connected to a model yet)\n",
        "# 10 filters, 3x3 kernel size, ReLU activation\n",
        "conv_layer = Conv2D(10, kernel_size=3, activation='relu')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Integrating into a Sequential Model\n",
        "We usually stack `Conv2D` layers with `Flatten` and `Dense` layers to create a classifier.\n",
        "\n",
        "*   **Conv2D**: Extracts features.\n",
        "*   **Flatten**: Converts 2D feature maps into a 1D vector.\n",
        "*   **Dense**: Performs classification based on the flattened vector.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten\n",
        "\n",
        "# Define image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# Initialize the model\n",
        "model = Sequential()\n",
        "\n",
        "# Add a Convolutional Layer\n",
        "# input_shape is required for the first layer: (height, width, channels)\n",
        "model.add(Conv2D(10, kernel_size=3, activation='relu', \n",
        "                 input_shape=(img_rows, img_cols, 1)))\n",
        "\n",
        "# Flatten the output of the convolution\n",
        "model.add(Flatten())\n",
        "\n",
        "# Add a Dense layer for classification (e.g., 3 classes)\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# View model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "---\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 5. Fitting a CNN</span><br>\n",
        "\n",
        "Once the model architecture is defined, we must compile and fit it to data.\n",
        "\n",
        "### Compilation\n",
        "We define the optimizer, loss function, and metrics.\n",
        "*   **Optimizer**: `adam` is a standard choice.\n",
        "*   **Loss**: `categorical_crossentropy` for multi-class classification.\n",
        "*   **Metrics**: `['accuracy']` to track performance.\n",
        "\n",
        "### Training (Fitting)\n",
        "We use `model.fit()` with training data, labels, and validation split.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Generate dummy data to make this cell executable\n",
        "# 50 images, 28x28 pixels, 1 channel (grayscale)\n",
        "train_data = np.random.random((50, 28, 28, 1))\n",
        "# One-hot encoded labels for 3 classes\n",
        "train_labels = tf.keras.utils.to_categorical(np.random.randint(3, size=(50, 1)), num_classes=3)\n",
        "\n",
        "# Test data\n",
        "test_data = np.random.random((10, 28, 28, 1))\n",
        "test_labels = tf.keras.utils.to_categorical(np.random.randint(3, size=(10, 1)), num_classes=3)\n",
        "\n",
        "# 1. Compile the model\n",
        "model.compile(optimizer='adam', \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(f\"Train Data Shape: {train_data.shape}\")\n",
        "\n",
        "# 2. Fit the model\n",
        "model.fit(train_data, train_labels, \n",
        "          validation_split=0.2, \n",
        "          epochs=3)\n",
        "\n",
        "# 3. Evaluate the model\n",
        "model.evaluate(test_data, test_labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "---\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 6. Tweaking Convolutions: Padding, Strides, and Dilation</span><br>\n",
        "\n",
        "We can alter the behavior of the convolution layer using specific parameters.\n",
        "\n",
        "### 1. Zero Padding (`padding`)\n",
        "When a kernel slides over an image, the output size naturally shrinks (as seen in Section 3). To prevent this, we can pad the input with zeros.\n",
        "\n",
        "| Padding Type | Description | Effect on Output Size |\n",
        "| :--- | :--- | :--- |\n",
        "| `'valid'` | No padding. Only valid positions are calculated. | Output shrinks. |\n",
        "| `'same'` | Zero padding added to input. | Output size equals Input size. |\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Zero Padding: 'valid' (Default)\n",
        "model.add(Conv2D(10, kernel_size=3, activation='relu', \n",
        "                 input_shape=(28, 28, 1), \n",
        "                 padding='valid'))\n",
        "\n",
        "# Zero Padding: 'same'\n",
        "model.add(Conv2D(10, kernel_size=3, activation='relu', \n",
        "                 input_shape=(28, 28, 1), \n",
        "                 padding='same'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 2. Strides (`strides`)\n",
        "The stride controls how many pixels the kernel moves at each step.\n",
        "*   **Stride 1**: Moves 1 pixel at a time (standard).\n",
        "*   **Stride 2**: Skips every other pixel (reduces output size by half).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stride = 1 (Default)\n",
        "model.add(Conv2D(10, kernel_size=3, activation='relu', \n",
        "                 input_shape=(28, 28, 1), \n",
        "                 strides=1))\n",
        "\n",
        "# Stride = 2 (Downsampling)\n",
        "model.add(Conv2D(10, kernel_size=3, activation='relu', \n",
        "                 input_shape=(28, 28, 1), \n",
        "                 strides=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 3. Dilated Convolutions (`dilation_rate`)\n",
        "Dilation introduces spaces between the kernel elements. This effectively increases the receptive field without increasing the number of parameters. It is useful for capturing larger scale patterns.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dilation Rate = 2\n",
        "model.add(Conv2D(10, kernel_size=3, activation='relu', \n",
        "                 input_shape=(28, 28, 1), \n",
        "                 dilation_rate=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "---\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 7. Calculating Output Sizes</span><br>\n",
        "\n",
        "It is crucial to understand how the input size changes as it passes through a convolutional layer. The formula for the output size $O$ is:\n",
        "\n",
        "$$ O = \\frac{I - K + 2P}{S} + 1 $$\n",
        "\n",
        "Where:\n",
        "*   $I$ = Size of the input\n",
        "*   $K$ = Size of the kernel\n",
        "*   $P$ = Size of zero padding\n",
        "*   $S$ = Strides\n",
        "\n",
        "### Calculation Examples\n",
        "1.  **Standard**: Input 28, Kernel 3, Padding 0, Stride 1.\n",
        "    $$ O = \\frac{28 - 3 + 0}{1} + 1 = 26 $$\n",
        "    *(Note: The PDF example uses specific padding logic, but generally 'valid' padding results in $I-K+1$)*.\n",
        "\n",
        "2.  **Strided**: Input 28, Kernel 3, Padding 1 (to keep 'same' logic roughly), Stride 1.\n",
        "    *   If we look at the PDF example: $28 = ((28 - 3 + 2)/1) + 1$. This implies $P=1$ (1 pixel on each side, total 2).\n",
        "\n",
        "### Python Calculation Helper\n",
        "We can write a function to calculate this automatically.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_output_size(input_size, kernel_size, padding_size, stride):\n",
        "    \"\"\"\n",
        "    Calculates the output dimension of a convolution layer.\n",
        "    \"\"\"\n",
        "    output = ((input_size - kernel_size + (2 * padding_size)) / stride) + 1\n",
        "    return output\n",
        "\n",
        "# Example 1: No padding, stride 1\n",
        "out1 = calculate_output_size(input_size=28, kernel_size=3, padding_size=0, stride=1)\n",
        "print(f\"Example 1 Output: {out1}\")\n",
        "\n",
        "# Example 2: Padding 1, stride 1 (Simulating 'same' for kernel 3)\n",
        "out2 = calculate_output_size(input_size=28, kernel_size=3, padding_size=1, stride=1)\n",
        "print(f\"Example 2 Output: {out2}\")\n",
        "\n",
        "# Example 3: Stride 3\n",
        "out3 = calculate_output_size(input_size=28, kernel_size=3, padding_size=1, stride=3)\n",
        "print(f\"Example 3 Output: {out3}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "---\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 8. Conclusion</span><br>\n",
        "\n",
        "In this notebook, we explored the fundamental mechanics of **Convolutions** and their implementation in **Keras**.\n",
        "\n",
        "### Key Takeaways\n",
        "1.  **Correlations**: Images have spatial structure; convolutions exploit this by looking at local neighborhoods of pixels.\n",
        "2.  **The Math**: A convolution is a sliding window operation involving element-wise multiplication and summation.\n",
        "3.  **Keras Implementation**: The `Conv2D` layer is the building block of CNNs. It is easily integrated into `Sequential` models.\n",
        "4.  **Hyperparameters**:\n",
        "    *   **Padding**: Controls output size (`'valid'` vs `'same'`).\n",
        "    *   **Strides**: Controls the step size (can downsample the image).\n",
        "    *   **Dilation**: Expands the receptive field without adding parameters.\n",
        "\n",
        "### Next Steps\n",
        "*   Experiment with different kernel sizes (e.g., 5x5 or 7x7).\n",
        "*   Try stacking multiple `Conv2D` layers to learn more complex features.\n",
        "*   Apply these concepts to real-world datasets like MNIST or CIFAR-10.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}