{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cce4e408",
      "metadata": {},
      "source": [
        "<div style=\"  background: linear-gradient(145deg, #0f172a, #1e293b);  border: 4px solid transparent;  border-radius: 14px;  padding: 18px 22px;  margin: 12px 0;  font-size: 26px;  font-weight: 600;  color: #f8fafc;  box-shadow: 0 6px 14px rgba(0,0,0,0.25);  background-clip: padding-box;  position: relative;\">  <div style=\"    position: absolute;    inset: 0;    padding: 4px;    border-radius: 14px;    background: linear-gradient(90deg, #06b6d4, #3b82f6, #8b5cf6);    -webkit-mask:       linear-gradient(#fff 0 0) content-box,       linear-gradient(#fff 0 0);    -webkit-mask-composite: xor;    mask-composite: exclude;    pointer-events: none;  \"></div>    <b>INTRODUCTION TO DEEP LEARNING WITH KERAS</b>    <br/>  <span style=\"color:#9ca3af; font-size: 18px; font-weight: 400;\">(Binary, Multi-class, Multi-label Classification & Callbacks)</span></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Table of Contents\n",
        "1. [Binary Classification](#section-1)\n",
        "2. [Multi-class Classification](#section-2)\n",
        "3. [Multi-label Classification](#section-3)\n",
        "4. [Keras Callbacks](#section-4)\n",
        "5. [Conclusion](#section-5)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e2ecb37",
      "metadata": {},
      "source": [
        "## <br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ğŸ§¾ 1. BINARY CLASSIFICATION</span><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a01d355",
      "metadata": {},
      "source": [
        "### 1.1 When to use Binary Classification?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f87ba53c",
      "metadata": {},
      "source": [
        "Binary classification is used when we need to distinguish between exactly two classes. A classic example is separating blue circles from red circles based on their coordinates.\n",
        "\n",
        "**The Dataset**\n",
        "The dataset typically consists of coordinates (features) and labels (targets). In this example, we have 2D coordinates and a binary label (0 or 1).\n",
        "\n",
        "| coordinates | labels |\n",
        "| :--- | :---: |\n",
        "| [0.242, 0.038] | 1 |\n",
        "| [0.044, -0.057] | 1 |\n",
        "| [-0.787, -0.076] | 0 |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "623ea37c",
      "metadata": {},
      "source": [
        "### 1.2 Visualizing Data with Pairplots"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3354f908",
      "metadata": {},
      "source": [
        "Before building a model, it is essential to visualize the data to understand the separability of the classes. We can use the `seaborn` library for this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b7f0892",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import make_circles\n",
        "\n",
        "# 1. Generate the \"Circles\" data\n",
        "# factor=0.3 makes the inner circle much smaller than the outer one\n",
        "X, y = make_circles(n_samples=1000, noise=0.1, factor=0.3, random_state=42)\n",
        "\n",
        "# 2. Put into a DataFrame for Seaborn\n",
        "df = pd.DataFrame(X, columns=['x1', 'x2'])\n",
        "df['class'] = y\n",
        "\n",
        "# 3. Visualize with Seaborn\n",
        "plt.figure(figsize=(8, 8))\n",
        "sns.scatterplot(data=df, x='x1', y='x2', hue='class', palette=['blue', 'red'], alpha=0.6)\n",
        "\n",
        "plt.title(\"Separate Blue from Red circles\")\n",
        "plt.xlim(-1.5, 1.5)\n",
        "plt.ylim(-1.5, 1.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07c682c6",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_circles\n",
        "\n",
        "# Generate synthetic data (circles)\n",
        "X, y = make_circles(n_samples=1000, noise=0.1, factor=0.2, random_state=42)\n",
        "\n",
        "# Create a DataFrame\n",
        "circles = pd.DataFrame({'x0': X[:, 0], 'x1': X[:, 1], 'target': y})\n",
        "\n",
        "# Plot a pairplot\n",
        "sns.pairplot(circles, hue=\"target\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6558f74e",
      "metadata": {},
      "source": [
        "### 1.3 Neural Network Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c103c56d",
      "metadata": {},
      "source": [
        "To solve this problem, we use a neural network.\n",
        "1.  **Input Layer:** Receives the coordinates.\n",
        "2.  **Hidden Layer:** Processes features (e.g., 4 neurons, `tanh` activation).\n",
        "3.  **Output Layer:** Produces the final prediction.\n",
        "\n",
        "<div style=\"background: #e0f2fe; border-left: 16px solid #0284c7; padding: 14px 18px; border-radius: 8px; font-size: 18px; color: #075985;\"> ğŸ’¡ <b>Tip:</b> For binary classification, the output layer typically uses the <b>Sigmoid</b> activation function. It transforms the neuron output into a probability between 0 and 1. </div>\n",
        "\n",
        "**The Sigmoid Function Logic:**\n",
        "$$ \\text{neuron output (3)} \\rightarrow \\text{sigmoid} \\rightarrow \\text{transformed output (0.95)} \\rightarrow \\text{rounded output (1)} $$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d6735f3",
      "metadata": {},
      "source": [
        "### 1.4 Building the Model in Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b96e1260",
      "metadata": {},
      "source": [
        "We will use the `Sequential` API from Keras to build the model layer by layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fcd2bc5",
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Instantiate a sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Add input and hidden layer\n",
        "# input_shape=(2,) corresponds to the x and y coordinates\n",
        "model.add(Dense(4, input_shape=(2,), activation='tanh'))\n",
        "\n",
        "# Add output layer, use sigmoid for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff7a9bf6",
      "metadata": {},
      "source": [
        "### 1.5 Compiling, Training, and Predicting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compile model\n",
        "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "# Using the 'circles' data \n",
        "# X contains coordinates, y contains labels\n",
        "model.fit(X, y, epochs=20, verbose=1)\n",
        "\n",
        "# Predict with trained model\n",
        "preds = model.predict(X)\n",
        "\n",
        "# Display first 5 predictions\n",
        "print(\"First 5 predictions:\\n\", preds[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b96064e",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "56ccfbde",
      "metadata": {},
      "source": [
        "### 1.6 Binary classification(`Breast Cancer` dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d448a25",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Load sklearn dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Build Keras model\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(16, activation=\"relu\", input_shape=(X_train.shape[1],)),\n",
        "    layers.Dense(8, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Train model\n",
        "model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_split=0.1,\n",
        "    verbose=2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de829bc6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "\n",
        "# Predict\n",
        "predictions = model.predict(X_test[:5])\n",
        "print(\"Probabilities:\", predictions)\n",
        "\n",
        "# Convert probabilities to class labels\n",
        "class_preds = (predictions > 0.5).astype(int)\n",
        "print(\"Predicted Classes:\", class_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "178174de",
      "metadata": {},
      "source": [
        "### 1.7 Binary classification (`Banknotes` dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df0a172e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   variace  skewness  curtosis  entropy  class\n",
            "0  3.62160    8.6661   -2.8073 -0.44699      0\n",
            "1  4.54590    8.1674   -2.4586 -1.46210      0\n",
            "2  3.86600   -2.6383    1.9242  0.10645      0\n",
            "3  3.45660    9.5228   -4.0112 -3.59440      0\n",
            "4  0.32924   -4.4552    4.5718 -0.98880      0\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "e:\\001_Github_Repo_all\\applied-deep-learning-keras\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4397 - loss: 0.7245 - val_accuracy: 0.4909 - val_loss: 0.6622\n",
            "Epoch 2/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5299 - loss: 0.6573 - val_accuracy: 0.6727 - val_loss: 0.6106\n",
            "Epoch 3/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6910 - loss: 0.5999 - val_accuracy: 0.7909 - val_loss: 0.5571\n",
            "Epoch 4/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8369 - loss: 0.5386 - val_accuracy: 0.9000 - val_loss: 0.4951\n",
            "Epoch 5/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9210 - loss: 0.4700 - val_accuracy: 0.9364 - val_loss: 0.4282\n",
            "Epoch 6/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9514 - loss: 0.3956 - val_accuracy: 0.9636 - val_loss: 0.3574\n",
            "Epoch 7/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9605 - loss: 0.3213 - val_accuracy: 0.9727 - val_loss: 0.2887\n",
            "Epoch 8/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9645 - loss: 0.2525 - val_accuracy: 0.9727 - val_loss: 0.2276\n",
            "Epoch 9/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9726 - loss: 0.1956 - val_accuracy: 0.9818 - val_loss: 0.1785\n",
            "Epoch 10/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9747 - loss: 0.1525 - val_accuracy: 0.9818 - val_loss: 0.1410\n",
            "Epoch 11/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9757 - loss: 0.1214 - val_accuracy: 0.9818 - val_loss: 0.1128\n",
            "Epoch 12/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9797 - loss: 0.0988 - val_accuracy: 0.9818 - val_loss: 0.0927\n",
            "Epoch 13/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9797 - loss: 0.0820 - val_accuracy: 0.9818 - val_loss: 0.0775\n",
            "Epoch 14/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9807 - loss: 0.0690 - val_accuracy: 0.9818 - val_loss: 0.0652\n",
            "Epoch 15/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9807 - loss: 0.0586 - val_accuracy: 0.9818 - val_loss: 0.0548\n",
            "Epoch 16/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9848 - loss: 0.0498 - val_accuracy: 0.9818 - val_loss: 0.0465\n",
            "Epoch 17/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9868 - loss: 0.0425 - val_accuracy: 0.9818 - val_loss: 0.0396\n",
            "Epoch 18/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9899 - loss: 0.0370 - val_accuracy: 1.0000 - val_loss: 0.0345\n",
            "Epoch 19/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9909 - loss: 0.0322 - val_accuracy: 1.0000 - val_loss: 0.0298\n",
            "Epoch 20/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9909 - loss: 0.0286 - val_accuracy: 1.0000 - val_loss: 0.0265\n",
            "\u001b[1m9/9\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9964 - loss: 0.0315 \n",
            "Test Accuracy: 0.996363639831543\n",
            "WARNING:tensorflow:6 out of the last 37 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001F05C151580> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "Predicted Probabilities: [[0.00976429]\n",
            " [0.21405722]\n",
            " [0.07634169]\n",
            " [0.00445213]\n",
            " [0.00723566]]\n",
            "Predicted Classes: [[0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Load CSV\n",
        "data = pd.read_csv(\"_datasets/banknotes.csv\")  # replace with correct path\n",
        "print(data.head())\n",
        "\n",
        "# Assume the last column is the label\n",
        "X = data.iloc[:, :-1].values\n",
        "y = data.iloc[:, -1].values\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Build Keras model\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(16, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    layers.Dense(8, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')  # binary classification\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train model\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_split=0.1\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "\n",
        "# Predict\n",
        "preds = model.predict(X_test[:5])\n",
        "print(\"Predicted Probabilities:\", preds)\n",
        "print(\"Predicted Classes:\", (preds > 0.5).astype(int))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f2a4048",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23562bd4",
      "metadata": {},
      "source": [
        "## <br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ğŸ§¾ 2. MULTI-CLASS CLASSIFICATION</span><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1616a6e8",
      "metadata": {},
      "source": [
        "### 2.1 The Concept"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c25e977a",
      "metadata": {},
      "source": [
        "Multi-class classification involves distinguishing between **more than two** classes.\n",
        "*   **Analogy:** Throwing darts where different regions correspond to different competitors (Steve, Susan, Michael, Kate).\n",
        "*   **Dataset:** Features (`xCoord`, `yCoord`) and a categorical target (`competitor`).\n",
        "\n",
        "**Example Dataset:**\n",
        "\n",
        "| xCoord | yCoord | competitor |\n",
        "| :--- | :--- | :--- |\n",
        "| -0.037673 | 0.057402 | Steve |\n",
        "| -0.331021 | -0.585035 | Susan |\n",
        "| -0.123567 | 0.839730 | Susan |\n",
        "| -0.086160 | 0.959787 | Michael |\n",
        "| -0.902632 | 0.078753 | Michael |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e6b8d6b",
      "metadata": {},
      "source": [
        "### 2.2 Architecture for Multi-Class"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7af35ee",
      "metadata": {},
      "source": [
        "The architecture changes slightly from binary classification:\n",
        "1.  **Input/Hidden Layers:** Similar structure (e.g., 128 -> 64 -> 32 neurons).\n",
        "2.  **Output Layer:** The number of neurons **must equal the number of classes**.\n",
        "3.  **Activation:** We use **Softmax**.\n",
        "\n",
        "**Softmax Output Example:**\n",
        "Softmax ensures all output probabilities sum to 1.\n",
        "- Michael: 0.6\n",
        "- Susan: 0.1\n",
        "- Kate: 0.2\n",
        "- Steve: 0.1\n",
        "- **Total:** 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14ed95cd",
      "metadata": {},
      "source": [
        "### 2.3 Building the Multi-Class Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dfc3eb0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a multi-class model\n",
        "mc_model = Sequential()\n",
        "\n",
        "# Input layer and first hidden layer\n",
        "mc_model.add(Dense(128, input_shape=(2,), activation='relu'))\n",
        "\n",
        "# Additional hidden layers\n",
        "mc_model.add(Dense(64, activation='relu'))\n",
        "mc_model.add(Dense(32, activation='relu'))\n",
        "\n",
        "# Output layer: 4 neurons (for 4 competitors), softmax activation\n",
        "mc_model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "mc_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d77bafd0",
      "metadata": {},
      "source": [
        "### 2.4 Categorical Cross-Entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56d8c851",
      "metadata": {},
      "source": [
        "For multi-class problems, the loss function is `categorical_crossentropy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a97f14b2",
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c152a63e",
      "metadata": {},
      "source": [
        "### 2.5 Preparing the Dataset (One-Hot Encoding)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c5df7b8",
      "metadata": {},
      "source": [
        "Neural networks cannot understand text labels like \"Steve\" or \"Susan\". We must convert them into numbers.\n",
        "1.  **Label Encoding:** Assign a number to each category (0, 1, 2, 3).\n",
        "2.  **One-Hot Encoding:** Create a binary vector for each category.\n",
        "\n",
        "**One-Hot Encoding Table:**\n",
        "\n",
        "| Food Name | Categorical # | Calories | $\\rightarrow$ | Apple | Chicken | Broccoli | Calories |\n",
        "| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |\n",
        "| Apple | 1 | 95 | | 1 | 0 | 0 | 95 |\n",
        "| Chicken | 2 | 231 | | 0 | 1 | 0 | 231 |\n",
        "| Broccoli | 3 | 50 | | 0 | 0 | 1 | 50 |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d447df86",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "# Turn response variable into labeled codes\n",
        "df.response = pd.Categorical(df.response)\n",
        "df.response = df.response.cat.codes\n",
        "\n",
        "# Turn response variable into one-hot response vector\n",
        "y = to_categorical(df.response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cb58fe1",
      "metadata": {},
      "source": [
        "**Enhanced Runnable Code (with dummy data):**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87b7f88a",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Create dummy data\n",
        "data = {\n",
        "    'xCoord': np.random.rand(5),\n",
        "    'yCoord': np.random.rand(5),\n",
        "    'competitor': ['Steve', 'Susan', 'Susan', 'Michael', 'Michael']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(\"Original Data:\\n\", df)\n",
        "\n",
        "# Turn response variable into labeled codes\n",
        "df['competitor_code'] = pd.Categorical(df['competitor']).codes\n",
        "\n",
        "print(\"\\nLabeled Codes:\\n\", df[['competitor', 'competitor_code']])\n",
        "\n",
        "# Turn response variable into one-hot response vector\n",
        "y_one_hot = to_categorical(df['competitor_code'])\n",
        "\n",
        "print(\"\\nOne-Hot Encoded Target:\\n\", y_one_hot)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d57856e",
      "metadata": {},
      "source": [
        "### 2.6 Multi-Class classification (`Iris` dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "249a2075",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "e:\\001_Github_Repo_all\\applied-deep-learning-keras\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.3056 - loss: 1.2022 - val_accuracy: 0.4167 - val_loss: 1.0788\n",
            "Epoch 2/30\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3148 - loss: 1.1432 - val_accuracy: 0.4167 - val_loss: 1.0530\n",
            "Epoch 3/30\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3333 - loss: 1.0882 - val_accuracy: 0.5000 - val_loss: 1.0284\n",
            "Epoch 4/30\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3426 - loss: 1.0381 - val_accuracy: 0.5000 - val_loss: 1.0049\n",
            "Epoch 5/30\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3611 - loss: 0.9897 - val_accuracy: 0.6667 - val_loss: 0.9801\n",
            "Epoch 6/30\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4537 - loss: 0.9436 - val_accuracy: 0.6667 - val_loss: 0.9539\n",
            "Epoch 7/30\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6111 - loss: 0.8983 - val_accuracy: 0.6667 - val_loss: 0.9286\n",
            "Epoch 8/30\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7315 - loss: 0.8559 - val_accuracy: 0.6667 - val_loss: 0.9022\n",
            "Epoch 9/30\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7500 - loss: 0.8147 - val_accuracy: 0.5833 - val_loss: 0.8770\n",
            "Epoch 10/30\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7593 - loss: 0.7765 - val_accuracy: 0.6667 - val_loss: 0.8512\n",
            "Epoch 11/30\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7685 - loss: 0.7400 - val_accuracy: 0.6667 - val_loss: 0.8259\n",
            "Epoch 12/30\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7685 - loss: 0.7057 - val_accuracy: 0.6667 - val_loss: 0.8014\n",
            "Epoch 13/30\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7685 - loss: 0.6721 - val_accuracy: 0.7500 - val_loss: 0.7769\n",
            "Epoch 14/30\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7778 - loss: 0.6411 - val_accuracy: 0.7500 - val_loss: 0.7529\n",
            "Epoch 15/30\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7870 - loss: 0.6117 - val_accuracy: 0.7500 - val_loss: 0.7305\n",
            "Epoch 16/30\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7963 - loss: 0.5842 - val_accuracy: 0.7500 - val_loss: 0.7086\n",
            "Epoch 17/30\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7963 - loss: 0.5586 - val_accuracy: 0.7500 - val_loss: 0.6879\n",
            "Epoch 18/30\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8148 - loss: 0.5348 - val_accuracy: 0.7500 - val_loss: 0.6697\n",
            "Epoch 19/30\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8148 - loss: 0.5125 - val_accuracy: 0.7500 - val_loss: 0.6526\n",
            "Epoch 20/30\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8148 - loss: 0.4930 - val_accuracy: 0.7500 - val_loss: 0.6359\n",
            "Epoch 21/30\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8148 - loss: 0.4749 - val_accuracy: 0.7500 - val_loss: 0.6212\n",
            "Epoch 22/30\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8148 - loss: 0.4589 - val_accuracy: 0.7500 - val_loss: 0.6089\n",
            "Epoch 23/30\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8241 - loss: 0.4435 - val_accuracy: 0.7500 - val_loss: 0.5965\n",
            "Epoch 24/30\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8241 - loss: 0.4299 - val_accuracy: 0.7500 - val_loss: 0.5837\n",
            "Epoch 25/30\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8241 - loss: 0.4174 - val_accuracy: 0.7500 - val_loss: 0.5729\n",
            "Epoch 26/30\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8241 - loss: 0.4056 - val_accuracy: 0.7500 - val_loss: 0.5622\n",
            "Epoch 27/30\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8241 - loss: 0.3952 - val_accuracy: 0.8333 - val_loss: 0.5511\n",
            "Epoch 28/30\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8241 - loss: 0.3849 - val_accuracy: 0.8333 - val_loss: 0.5413\n",
            "Epoch 29/30\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8241 - loss: 0.3760 - val_accuracy: 0.8333 - val_loss: 0.5328\n",
            "Epoch 30/30\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8241 - loss: 0.3670 - val_accuracy: 0.8333 - val_loss: 0.5222\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x1f059d55ae0>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load sklearn dataset (3 classes)\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target  # classes: 0, 1, 2 [setosa, versicolor, virginica]\n",
        "\n",
        "# One-hot encode labels\n",
        "y = to_categorical(y, num_classes=3)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Build Keras model\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(16, activation=\"relu\", input_shape=(X_train.shape[1],)),\n",
        "    layers.Dense(8, activation=\"relu\"),\n",
        "    layers.Dense(3, activation=\"softmax\")  # 3 classes\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Train model\n",
        "model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=30,\n",
        "    batch_size=16,\n",
        "    validation_split=0.1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "c292af37",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8667 - loss: 0.3344\n",
            "Test Accuracy: 0.8666666746139526\n",
            "WARNING:tensorflow:5 out of the last 36 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001F059EDA480> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
            "Class probabilities:\n",
            " [[0.11653354 0.41802305 0.46544343]\n",
            " [0.94040805 0.02456246 0.03502943]\n",
            " [0.00176584 0.07241853 0.92581564]\n",
            " [0.0907075  0.39806685 0.5112257 ]\n",
            " [0.05511475 0.35034245 0.5945428 ]]\n",
            "Predicted Classes: [2 0 2 2 2]\n"
          ]
        }
      ],
      "source": [
        "# Evaluate model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "\n",
        "# Predict\n",
        "predictions = model.predict(X_test[:5])\n",
        "print(\"Class probabilities:\\n\", predictions)\n",
        "\n",
        "# Convert probabilities to class labels\n",
        "class_preds = np.argmax(predictions, axis=1)\n",
        "print(\"Predicted Classes:\", class_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "713148ac",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1d3e197",
      "metadata": {},
      "source": [
        "## <br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ğŸ§¾ 3. MULTI-LABEL CLASSIFICATION</span><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ef1e05e",
      "metadata": {},
      "source": [
        "### 3.1 The Concept"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0e38a5e",
      "metadata": {},
      "source": [
        "In multi-label classification, a single instance can belong to **multiple classes** simultaneously.\n",
        "- **Example:** A TV show like *Game of Thrones* can be tagged as \"Action\", \"Adventure\", AND \"Drama\".\n",
        "- **Irrigation Machine Example:** A sensor reading might indicate multiple parcels of land need water simultaneously."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8b76a6e",
      "metadata": {},
      "source": [
        "### 3.2 Architecture Differences"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4145c9ee",
      "metadata": {},
      "source": [
        "- **Multi-Class:** Uses `softmax` (probabilities sum to 1, classes are mutually exclusive).\n",
        "- **Multi-Label:** Uses `sigmoid` on the output layer. Each neuron outputs a probability between 0 and 1 independently of the others.\n",
        "\n",
        "**Comparison:**\n",
        "\n",
        "| Feature | Multi-Class | Multi-Label |\n",
        "| :--- | :--- | :--- |\n",
        "| **Example** | Sun OR Moon OR Cloud | Sun AND Cloud |\n",
        "| **Labels** | [0 0 1] (Only one active) | [1 0 1] (Multiple active) |\n",
        "| **Activation** | Softmax | Sigmoid |\n",
        "| **Loss** | Categorical Cross-entropy | Binary Cross-entropy |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1565595c",
      "metadata": {},
      "source": [
        "### 3.3 Building the Multi-Label Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "b943c7da",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - accuracy: 0.3125 - loss: 0.7249 - val_accuracy: 0.4000 - val_loss: 0.6870\n",
            "Epoch 2/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3125 - loss: 0.7222 - val_accuracy: 0.4000 - val_loss: 0.6871\n",
            "Epoch 3/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3125 - loss: 0.7189 - val_accuracy: 0.3500 - val_loss: 0.6881\n",
            "Epoch 4/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3250 - loss: 0.7163 - val_accuracy: 0.3000 - val_loss: 0.6893\n",
            "Epoch 5/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.3375 - loss: 0.7140 - val_accuracy: 0.3000 - val_loss: 0.6907\n",
            "Epoch 6/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3375 - loss: 0.7124 - val_accuracy: 0.3000 - val_loss: 0.6923\n",
            "Epoch 7/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3375 - loss: 0.7104 - val_accuracy: 0.3000 - val_loss: 0.6940\n",
            "Epoch 8/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3375 - loss: 0.7087 - val_accuracy: 0.3000 - val_loss: 0.6950\n",
            "Epoch 9/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3375 - loss: 0.7072 - val_accuracy: 0.3000 - val_loss: 0.6955\n",
            "Epoch 10/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3375 - loss: 0.7056 - val_accuracy: 0.3000 - val_loss: 0.6956\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import numpy as np\n",
        "\n",
        "# Generate dummy multi-label data\n",
        "# 100 samples, 10 features\n",
        "X_train = np.random.random((100, 10))\n",
        "# 100 samples, 3 possible labels (0 or 1 for each)\n",
        "y_train = np.random.randint(2, size=(100, 3))\n",
        "\n",
        "# Instantiate model\n",
        "ml_model = Sequential()\n",
        "\n",
        "# Add input and hidden layers\n",
        "ml_model.add(Dense(16, input_shape=(10,), activation='relu'))\n",
        "\n",
        "# Add an output layer for the 3 classes and sigmoid activation\n",
        "# Sigmoid allows each output node to independently be close to 0 or 1\n",
        "ml_model.add(Dense(3, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with binary crossentropy\n",
        "ml_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "# validation_split creates a validation set automatically\n",
        "history = ml_model.fit(X_train, y_train, epochs=10, validation_split=0.2, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e70a6d06",
      "metadata": {},
      "source": [
        "### 3.4 Multi-Label Model (`darts` dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25518e74",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     xCoord    yCoord  Kate  Michael  Steve  Susan\n",
            "0  0.196451 -0.520341   0.0      0.0    1.0    0.0\n",
            "1  0.476027 -0.306763   0.0      0.0    0.0    1.0\n",
            "2  0.003175 -0.980736   0.0      1.0    0.0    0.0\n",
            "3  0.294078  0.267566   1.0      0.0    0.0    0.0\n",
            "4 -0.051120  0.598946   0.0      0.0    1.0    0.0\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "e:\\001_Github_Repo_all\\applied-deep-learning-keras\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18/18 - 1s - 60ms/step - accuracy: 0.2361 - loss: 0.6906 - val_accuracy: 0.2031 - val_loss: 0.6813\n",
            "Epoch 2/30\n",
            "18/18 - 0s - 6ms/step - accuracy: 0.2378 - loss: 0.6639 - val_accuracy: 0.2031 - val_loss: 0.6608\n",
            "Epoch 3/30\n",
            "18/18 - 0s - 7ms/step - accuracy: 0.2378 - loss: 0.6406 - val_accuracy: 0.2031 - val_loss: 0.6395\n",
            "Epoch 4/30\n",
            "18/18 - 0s - 6ms/step - accuracy: 0.2500 - loss: 0.6177 - val_accuracy: 0.2031 - val_loss: 0.6191\n",
            "Epoch 5/30\n",
            "18/18 - 0s - 6ms/step - accuracy: 0.2483 - loss: 0.5964 - val_accuracy: 0.2031 - val_loss: 0.6000\n",
            "Epoch 6/30\n",
            "18/18 - 0s - 6ms/step - accuracy: 0.2483 - loss: 0.5778 - val_accuracy: 0.2031 - val_loss: 0.5844\n",
            "Epoch 7/30\n",
            "18/18 - 0s - 6ms/step - accuracy: 0.2500 - loss: 0.5645 - val_accuracy: 0.2031 - val_loss: 0.5743\n",
            "Epoch 8/30\n",
            "18/18 - 0s - 6ms/step - accuracy: 0.2760 - loss: 0.5565 - val_accuracy: 0.2344 - val_loss: 0.5686\n",
            "Epoch 9/30\n",
            "18/18 - 0s - 7ms/step - accuracy: 0.2882 - loss: 0.5516 - val_accuracy: 0.2500 - val_loss: 0.5634\n",
            "Epoch 10/30\n",
            "18/18 - 0s - 6ms/step - accuracy: 0.2917 - loss: 0.5479 - val_accuracy: 0.2500 - val_loss: 0.5599\n",
            "Epoch 11/30\n",
            "18/18 - 0s - 6ms/step - accuracy: 0.2951 - loss: 0.5448 - val_accuracy: 0.2500 - val_loss: 0.5574\n",
            "Epoch 12/30\n",
            "18/18 - 0s - 6ms/step - accuracy: 0.3073 - loss: 0.5412 - val_accuracy: 0.2500 - val_loss: 0.5531\n",
            "Epoch 13/30\n",
            "18/18 - 0s - 6ms/step - accuracy: 0.3142 - loss: 0.5382 - val_accuracy: 0.2656 - val_loss: 0.5500\n",
            "Epoch 14/30\n",
            "18/18 - 0s - 6ms/step - accuracy: 0.3299 - loss: 0.5348 - val_accuracy: 0.2656 - val_loss: 0.5455\n",
            "Epoch 15/30\n",
            "18/18 - 0s - 6ms/step - accuracy: 0.3333 - loss: 0.5313 - val_accuracy: 0.2500 - val_loss: 0.5423\n",
            "Epoch 16/30\n",
            "18/18 - 0s - 6ms/step - accuracy: 0.3767 - loss: 0.5277 - val_accuracy: 0.2969 - val_loss: 0.5375\n",
            "Epoch 17/30\n",
            "18/18 - 0s - 6ms/step - accuracy: 0.4028 - loss: 0.5239 - val_accuracy: 0.2969 - val_loss: 0.5340\n",
            "Epoch 18/30\n",
            "18/18 - 0s - 7ms/step - accuracy: 0.4219 - loss: 0.5199 - val_accuracy: 0.3125 - val_loss: 0.5290\n",
            "Epoch 19/30\n",
            "18/18 - 0s - 6ms/step - accuracy: 0.4462 - loss: 0.5159 - val_accuracy: 0.3750 - val_loss: 0.5244\n",
            "Epoch 20/30\n",
            "18/18 - 0s - 6ms/step - accuracy: 0.4601 - loss: 0.5116 - val_accuracy: 0.4062 - val_loss: 0.5197\n",
            "Epoch 21/30\n",
            "18/18 - 0s - 6ms/step - accuracy: 0.4774 - loss: 0.5074 - val_accuracy: 0.4375 - val_loss: 0.5143\n",
            "Epoch 22/30\n",
            "18/18 - 0s - 6ms/step - accuracy: 0.4983 - loss: 0.5032 - val_accuracy: 0.4375 - val_loss: 0.5092\n",
            "Epoch 23/30\n",
            "18/18 - 0s - 6ms/step - accuracy: 0.5122 - loss: 0.4992 - val_accuracy: 0.4375 - val_loss: 0.5037\n",
            "Epoch 24/30\n",
            "18/18 - 0s - 6ms/step - accuracy: 0.5156 - loss: 0.4943 - val_accuracy: 0.4688 - val_loss: 0.4980\n",
            "Epoch 25/30\n",
            "18/18 - 0s - 6ms/step - accuracy: 0.5139 - loss: 0.4900 - val_accuracy: 0.4688 - val_loss: 0.4928\n",
            "Epoch 26/30\n",
            "18/18 - 0s - 6ms/step - accuracy: 0.5174 - loss: 0.4853 - val_accuracy: 0.5469 - val_loss: 0.4872\n",
            "Epoch 27/30\n",
            "18/18 - 0s - 6ms/step - accuracy: 0.5330 - loss: 0.4799 - val_accuracy: 0.5156 - val_loss: 0.4814\n",
            "Epoch 28/30\n",
            "18/18 - 0s - 6ms/step - accuracy: 0.5417 - loss: 0.4746 - val_accuracy: 0.5156 - val_loss: 0.4745\n",
            "Epoch 29/30\n",
            "18/18 - 0s - 6ms/step - accuracy: 0.5382 - loss: 0.4694 - val_accuracy: 0.5469 - val_loss: 0.4672\n",
            "Epoch 30/30\n",
            "18/18 - 0s - 6ms/step - accuracy: 0.5538 - loss: 0.4638 - val_accuracy: 0.5312 - val_loss: 0.4600\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x1f053dedf30>"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "\n",
        "# Load darts.csv\n",
        "data = pd.read_csv(\"_datasets/darts.csv\")\n",
        "\n",
        "# Preprocess for Multi-Label (One-Hot Encoding)\n",
        "data = pd.get_dummies(data, columns=['competitor'], prefix='', prefix_sep='')\n",
        "data = data.astype(float)\n",
        "print(data.head())\n",
        "\n",
        "# Separate features and targets\n",
        "# xCoord, yCoord are features\n",
        "X = data[['xCoord', 'yCoord']].values\n",
        "y = data.drop(['xCoord', 'yCoord'], axis=1).values\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Build Keras model\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    layers.Dense(16, activation='relu'),\n",
        "    layers.Dense(y.shape[1], activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train model\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    validation_split=0.1,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "a7f49d4c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4625 - loss: 0.4819 \n",
            "Test Accuracy: 0.4625000059604645\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "Predicted Labels:\n",
            " [[0 0 0 0]\n",
            " [0 0 0 0]\n",
            " [0 0 0 0]\n",
            " [0 0 0 0]\n",
            " [0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "# Evaluate\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "\n",
        "# Predict\n",
        "preds = model.predict(X_test[:5])\n",
        "label_preds = (preds > 0.5).astype(int)\n",
        "print(\"Predicted Labels:\\n\", label_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8ab10ad",
      "metadata": {},
      "source": [
        "### 3.5 Multi-Label Model (`irrigation_machine` dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf8ac92e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Unnamed: 0  sensor_0  sensor_1  sensor_2  sensor_3  sensor_4  sensor_5  \\\n",
            "0           0       1.0       2.0       1.0       7.0       0.0       1.0   \n",
            "1           1       5.0       1.0       3.0       5.0       2.0       2.0   \n",
            "2           2       3.0       1.0       4.0       3.0       4.0       0.0   \n",
            "3           3       2.0       2.0       4.0       3.0       5.0       0.0   \n",
            "4           4       4.0       3.0       3.0       2.0       5.0       1.0   \n",
            "\n",
            "   sensor_6  sensor_7  sensor_8  ...  sensor_13  sensor_14  sensor_15  \\\n",
            "0       1.0       4.0       0.0  ...        8.0        1.0        0.0   \n",
            "1       1.0       2.0       3.0  ...        4.0        5.0        5.0   \n",
            "2       1.0       6.0       0.0  ...        3.0        3.0        1.0   \n",
            "3       3.0       2.0       2.0  ...        4.0        1.0        1.0   \n",
            "4       3.0       1.0       1.0  ...        1.0        3.0        2.0   \n",
            "\n",
            "   sensor_16  sensor_17  sensor_18  sensor_19  parcel_0  parcel_1  parcel_2  \n",
            "0        2.0        1.0        9.0        2.0         0         1         0  \n",
            "1        2.0        2.0        2.0        7.0         0         0         0  \n",
            "2        0.0        3.0        1.0        0.0         1         1         0  \n",
            "3        4.0        1.0        3.0        2.0         0         0         0  \n",
            "4        2.0        1.0        1.0        0.0         1         1         0  \n",
            "\n",
            "[5 rows x 24 columns]\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "e:\\001_Github_Repo_all\\applied-deep-learning-keras\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "45/45 - 1s - 25ms/step - accuracy: 0.7354 - loss: 0.1074 - val_accuracy: 0.9000 - val_loss: -6.7699e-01\n",
            "Epoch 2/30\n",
            "45/45 - 0s - 3ms/step - accuracy: 0.8076 - loss: -1.0505e+00 - val_accuracy: 0.9000 - val_loss: -2.7618e+00\n",
            "Epoch 3/30\n",
            "45/45 - 0s - 4ms/step - accuracy: 0.8076 - loss: -3.5776e+00 - val_accuracy: 0.9000 - val_loss: -7.8909e+00\n",
            "Epoch 4/30\n",
            "45/45 - 0s - 3ms/step - accuracy: 0.8076 - loss: -9.4583e+00 - val_accuracy: 0.9000 - val_loss: -1.8770e+01\n",
            "Epoch 5/30\n",
            "45/45 - 0s - 3ms/step - accuracy: 0.8076 - loss: -2.0893e+01 - val_accuracy: 0.9000 - val_loss: -3.9137e+01\n",
            "Epoch 6/30\n",
            "45/45 - 0s - 3ms/step - accuracy: 0.8076 - loss: -4.1590e+01 - val_accuracy: 0.9000 - val_loss: -7.1809e+01\n",
            "Epoch 7/30\n",
            "45/45 - 0s - 3ms/step - accuracy: 0.8076 - loss: -7.4947e+01 - val_accuracy: 0.9000 - val_loss: -1.2490e+02\n",
            "Epoch 8/30\n",
            "45/45 - 0s - 3ms/step - accuracy: 0.8076 - loss: -1.2491e+02 - val_accuracy: 0.9000 - val_loss: -2.0013e+02\n",
            "Epoch 9/30\n",
            "45/45 - 0s - 3ms/step - accuracy: 0.8076 - loss: -1.9513e+02 - val_accuracy: 0.9000 - val_loss: -3.0042e+02\n",
            "Epoch 10/30\n",
            "45/45 - 0s - 3ms/step - accuracy: 0.8076 - loss: -2.8719e+02 - val_accuracy: 0.9000 - val_loss: -4.3139e+02\n",
            "Epoch 11/30\n",
            "45/45 - 0s - 3ms/step - accuracy: 0.8076 - loss: -4.0498e+02 - val_accuracy: 0.9000 - val_loss: -5.9760e+02\n",
            "Epoch 12/30\n",
            "45/45 - 0s - 4ms/step - accuracy: 0.8076 - loss: -5.5234e+02 - val_accuracy: 0.9000 - val_loss: -7.9305e+02\n",
            "Epoch 13/30\n",
            "45/45 - 0s - 3ms/step - accuracy: 0.8076 - loss: -7.2945e+02 - val_accuracy: 0.9000 - val_loss: -1.0299e+03\n",
            "Epoch 14/30\n",
            "45/45 - 0s - 4ms/step - accuracy: 0.8076 - loss: -9.3882e+02 - val_accuracy: 0.9000 - val_loss: -1.3052e+03\n",
            "Epoch 15/30\n",
            "45/45 - 0s - 4ms/step - accuracy: 0.8076 - loss: -1.1793e+03 - val_accuracy: 0.9000 - val_loss: -1.6340e+03\n",
            "Epoch 16/30\n",
            "45/45 - 0s - 3ms/step - accuracy: 0.8076 - loss: -1.4581e+03 - val_accuracy: 0.9000 - val_loss: -1.9948e+03\n",
            "Epoch 17/30\n",
            "45/45 - 0s - 4ms/step - accuracy: 0.8076 - loss: -1.7690e+03 - val_accuracy: 0.9000 - val_loss: -2.3988e+03\n",
            "Epoch 18/30\n",
            "45/45 - 0s - 3ms/step - accuracy: 0.8076 - loss: -2.1142e+03 - val_accuracy: 0.9000 - val_loss: -2.8529e+03\n",
            "Epoch 19/30\n",
            "45/45 - 0s - 4ms/step - accuracy: 0.8076 - loss: -2.5055e+03 - val_accuracy: 0.9000 - val_loss: -3.3474e+03\n",
            "Epoch 20/30\n",
            "45/45 - 0s - 3ms/step - accuracy: 0.8076 - loss: -2.9337e+03 - val_accuracy: 0.9000 - val_loss: -3.9148e+03\n",
            "Epoch 21/30\n",
            "45/45 - 0s - 4ms/step - accuracy: 0.8076 - loss: -3.4195e+03 - val_accuracy: 0.9000 - val_loss: -4.5336e+03\n",
            "Epoch 22/30\n",
            "45/45 - 0s - 3ms/step - accuracy: 0.8076 - loss: -3.9536e+03 - val_accuracy: 0.9000 - val_loss: -5.2236e+03\n",
            "Epoch 23/30\n",
            "45/45 - 0s - 4ms/step - accuracy: 0.8076 - loss: -4.5431e+03 - val_accuracy: 0.9000 - val_loss: -5.9835e+03\n",
            "Epoch 24/30\n",
            "45/45 - 0s - 3ms/step - accuracy: 0.8076 - loss: -5.1951e+03 - val_accuracy: 0.9000 - val_loss: -6.8063e+03\n",
            "Epoch 25/30\n",
            "45/45 - 0s - 4ms/step - accuracy: 0.8076 - loss: -5.9045e+03 - val_accuracy: 0.9000 - val_loss: -7.7160e+03\n",
            "Epoch 26/30\n",
            "45/45 - 0s - 3ms/step - accuracy: 0.8076 - loss: -6.6806e+03 - val_accuracy: 0.9000 - val_loss: -8.6753e+03\n",
            "Epoch 27/30\n",
            "45/45 - 0s - 3ms/step - accuracy: 0.8076 - loss: -7.5009e+03 - val_accuracy: 0.9000 - val_loss: -9.7438e+03\n",
            "Epoch 28/30\n",
            "45/45 - 0s - 3ms/step - accuracy: 0.8076 - loss: -8.4034e+03 - val_accuracy: 0.9000 - val_loss: -1.0828e+04\n",
            "Epoch 29/30\n",
            "45/45 - 0s - 4ms/step - accuracy: 0.8076 - loss: -9.3338e+03 - val_accuracy: 0.9000 - val_loss: -1.2071e+04\n",
            "Epoch 30/30\n",
            "45/45 - 0s - 3ms/step - accuracy: 0.8076 - loss: -1.0356e+04 - val_accuracy: 0.9000 - val_loss: -1.3331e+04\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x1f053ec58d0>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "\n",
        "# Load irrigation_machine.csv\n",
        "data = pd.read_csv(\"_datasets/irrigation_machine.csv\")\n",
        "print(data.head())\n",
        "\n",
        "# Assuming last N columns are multi-label targets\n",
        "num_labels = 4  # change according to dataset\n",
        "X = data.iloc[:, :-num_labels].values\n",
        "y = data.iloc[:, -num_labels:].values\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Build Keras model\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(y.shape[1], activation='sigmoid')  # multi-label output\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train model\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    validation_split=0.1,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "97da3708",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4437 - loss: 0.4471 \n",
            "Test Accuracy: 0.4437499940395355\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Predicted Labels:\n",
            " [[0 0 1 0]\n",
            " [0 0 0 0]\n",
            " [0 0 1 0]\n",
            " [0 0 0 0]\n",
            " [0 0 1 0]]\n"
          ]
        }
      ],
      "source": [
        "# Evaluate\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "\n",
        "# Predict\n",
        "preds = model.predict(X_test[:5])\n",
        "label_preds = (preds > 0.5).astype(int)\n",
        "print(\"Predicted Labels:\\n\", label_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2f4a0aa",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8785722",
      "metadata": {},
      "source": [
        "## <br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ğŸ§¾ 4. KERAS CALLBACKS</span><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63cd8347",
      "metadata": {},
      "source": [
        "### 4.1 What is a Callback?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c585adc",
      "metadata": {},
      "source": [
        "A callback is a set of functions to be applied at given stages of the training procedure. You can use callbacks to get a view on internal states and statistics of the model during training."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4c272c6",
      "metadata": {},
      "source": [
        "### 4.2 The History Callback"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `fit()` method returns a `History` object. This object has a member `history`, which is a dictionary containing data about everything that happened during training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "**Plotting History:**\n",
        "We can visualize the training progress using Matplotlib.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5323d79d",
      "metadata": {},
      "source": [
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot train vs test accuracy per epoch\n",
        "plt.figure()\n",
        "\n",
        "# Use the history metrics\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "\n",
        "# Make it pretty\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'])\n",
        "plt.show()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d5b5a6d",
      "metadata": {},
      "source": [
        "### 4.3 Early Stopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Early stopping is a technique to prevent overfitting. It stops training when a monitored metric (like validation loss) has stopped improving.\n",
        "\n",
        "<div style=\"background: #e0f2fe; border-left: 16px solid #0284c7; padding: 14px 18px; border-radius: 8px; font-size: 18px; color: #075985;\"> ğŸ’¡ <b>Tip:</b> The `patience` parameter determines how many epochs to wait after the metric stops improving before actually stopping the training. </div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7eccb20f",
      "metadata": {},
      "source": [
        "```python\n",
        "# Import early stopping from keras callbacks\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Instantiate an early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "# Train your model with the callback\n",
        "model.fit(X_train, y_train, epochs=100,\n",
        "          validation_data=(X_test, y_test),\n",
        "          callbacks=[early_stopping]\n",
        "          )\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "348a524d",
      "metadata": {},
      "source": [
        "### 4.4 Model Checkpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- `ModelCheckpoint` saves the model at some interval, so the model can be loaded later to continue training from the state saved. \n",
        "\n",
        "- `save_best_only=True` ensures you only save the model when it performs better than previous epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fe1b87c",
      "metadata": {},
      "source": [
        "```python\n",
        "# Import model checkpoint from keras callbacks\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Instantiate a model checkpoint callback\n",
        "model_save = ModelCheckpoint('best_model.hdf5', save_best_only=True)\n",
        "\n",
        "# Train your model with the callback\n",
        "model.fit(X_train, y_train, epochs=100,\n",
        "          validation_data=(X_test, y_test),\n",
        "          callbacks=[model_save])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f92c3383",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "359ffa5f",
      "metadata": {},
      "source": [
        "```python\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# 1. Define Early Stopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
        "\n",
        "# 2. Define Model Checkpoint\n",
        "# We use a temporary filename for the example\n",
        "checkpoint = ModelCheckpoint('best_run_model.keras', save_best_only=True, verbose=1)\n",
        "\n",
        "# 3. Train with both callbacks\n",
        "# Using the multi-label model and data from the previous section\n",
        "history_cb = ml_model.fit(\n",
        "    X_train, y_train, \n",
        "    epochs=50, \n",
        "    validation_split=0.2, \n",
        "    callbacks=[early_stop, checkpoint],\n",
        "    verbose=0 # Silencing output for brevity in notebook\n",
        ")\n",
        "\n",
        "print(\"Training finished.\")\n",
        "print(f\"Stopped at epoch: {len(history_cb.history['loss'])}\")\n",
        "```\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3de6aec3",
      "metadata": {},
      "source": [
        "### 4.5 Multi-Class classification (`Iris` dataset) ~ **Callbacks** -> `EarlyStopping`, `ModelCheckpoint` and `ReduceLROnPlateau`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a89f802e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau # import callbacks\n",
        "\n",
        "# -----------------------------\n",
        "# Load Digits dataset\n",
        "# -----------------------------\n",
        "X = np.load(\"_datasets/Digits/digits_pixels.npy\")  # shape: (n_samples, n_features)\n",
        "y = np.load(\"_datasets/Digits/digits_target.npy\")  # shape: (n_samples,)\n",
        "\n",
        "num_classes = len(np.unique(y))\n",
        "y = to_categorical(y, num_classes=num_classes)\n",
        "\n",
        "# -----------------------------\n",
        "# Train-test split\n",
        "# -----------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# Feature scaling\n",
        "# -----------------------------\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# -----------------------------\n",
        "# Build Keras model\n",
        "# -----------------------------\n",
        "model = keras.Sequential([\n",
        "    keras.Input(shape=(X_train.shape[1],)),  # recommended Input layer\n",
        "    layers.Dense(64, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001)),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(32, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001)),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(num_classes, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# -----------------------------\n",
        "# Compile model\n",
        "# -----------------------------\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# Callbacks\n",
        "# -----------------------------\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True), # stop training when validation loss stops improving\n",
        "    ModelCheckpoint('best_digits_model.keras', save_best_only=True),          # save the best model\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)             # reduce learning rate when validation loss stops improving\n",
        "]\n",
        "\n",
        "# -----------------------------\n",
        "# Train model\n",
        "# -----------------------------\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_split=0.1,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# Evaluate model\n",
        "# -----------------------------\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Predict on first 10 test samples\n",
        "# -----------------------------\n",
        "predictions = model.predict(X_test[:10])\n",
        "class_preds = np.argmax(predictions, axis=1)\n",
        "true_classes = np.argmax(y_test[:10], axis=1)\n",
        "\n",
        "print(\"Predicted Classes:\", class_preds)\n",
        "print(\"True Classes     :\", true_classes)\n",
        "\n",
        "# -----------------------------\n",
        "# Visualize predictions\n",
        "# -----------------------------\n",
        "plt.figure(figsize=(12, 4))\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i+1)\n",
        "    plt.imshow(X_test[i].reshape(8, 8), cmap='gray')  # adjust shape if necessary\n",
        "    plt.title(f\"P: {class_preds[i]}, T: {true_classes[i]}\")\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d620da7b",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ğŸ§¾ 5. CONCLUSION</span><br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48c04110",
      "metadata": {},
      "source": [
        "### **1. Binary Classification**\n",
        "\n",
        "* **Use case:** 2 classes (e.g., spam vs. not spam)\n",
        "* **Model output:**  = `1 neuron`\n",
        "* **Activation:** `sigmoid`\n",
        "* **Loss function:** `binary_crossentropy`\n",
        "* **Metrics:** `accuracy`, `AUC`\n",
        "\n",
        "```python\n",
        "model = Sequential([\n",
        "    Dense(16, activation='relu', input_shape=(input_dim,)),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Multi-Class Classification**\n",
        "\n",
        "* **Use case:** >2 mutually exclusive classes (e.g., digit recognition 0â€“9)\n",
        "* **Model output:** `Number of neurons = number of classes`\n",
        "* **Activation:** `softmax`\n",
        "* **Loss function:** `categorical_crossentropy`\n",
        "* **Data prep:** One-hot encode labels (`to_categorical`)\n",
        "* **Metrics:** `accuracy`\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train_encoded = to_categorical(y_train, num_classes)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Multi-Label Classification**\n",
        "\n",
        "* **Use case:** Items can belong to multiple classes (e.g., image tagging)\n",
        "* **Model output:** Number of neurons = number of possible labels\n",
        "* **Activation:** `sigmoid` (per neuron)\n",
        "* **Loss function:** `binary_crossentropy`\n",
        "* **Metrics:** `accuracy`, `AUC`\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Callbacks**\n",
        "\n",
        "* **`History`** â€“ Logs training & validation metrics for plotting\n",
        "* **`EarlyStopping`** â€“ Stop training when validation loss stops improving\n",
        "* **`ModelCheckpoint`** â€“ Save the best model during training\n",
        "* **`ReduceLROnPlateau`** â€“ Reduce learning rate when metrics plateau\n",
        "\n",
        "```python\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
        "    ModelCheckpoint('best_model.h5', save_best_only=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
        "]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **5. Common Optimizers**\n",
        "\n",
        "| Optimizer | Key Notes                                      |\n",
        "| --------- | ---------------------------------------------- |\n",
        "| SGD       | Basic, allows momentum and learning rate decay |\n",
        "| Adam      | Adaptive learning rates, widely used           |\n",
        "| RMSprop   | Good for RNNs or online learning               |\n",
        "| Adagrad   | Good for sparse data                           |\n",
        "\n",
        "---\n",
        "\n",
        "### **6. Common Activation Functions**\n",
        "\n",
        "| Activation | Use Case                                  |\n",
        "| ---------- | ----------------------------------------- |\n",
        "| ReLU       | Hidden layers, most common                |\n",
        "| Sigmoid    | Binary classification output              |\n",
        "| Softmax    | Multi-class output                        |\n",
        "| Tanh       | Hidden layers, sometimes better than ReLU |\n",
        "\n",
        "---\n",
        "\n",
        "### **7. Metrics Overview**\n",
        "\n",
        "* **Accuracy** â€“ Correct predictions / total\n",
        "* **Precision / Recall / F1-score** â€“ Important for imbalanced datasets\n",
        "* **AUC-ROC** â€“ Probability ranking quality\n",
        "\n",
        "---\n",
        "\n",
        "### **8. Data Preprocessing Tips**\n",
        "\n",
        "* **Normalization:** `x = (x - mean) / std` or `x = x / 255` for images\n",
        "* **One-Hot Encoding:** For multi-class classification\n",
        "* **Train/Validation Split:** `train_test_split` or `validation_split` in `model.fit`\n",
        "\n",
        "---\n",
        "\n",
        "### **9. Training Tips**\n",
        "\n",
        "* Start simple â†’ few layers, small neurons\n",
        "* Use dropout to prevent overfitting\n",
        "* Monitor training vs. validation loss for overfitting signs\n",
        "* Batch size: 32â€“128 (common), tune for your dataset\n",
        "* Epochs: Start small (10â€“50), use EarlyStopping\n",
        "\n",
        "---\n",
        "\n",
        "### **10. Next Steps / Experiments**\n",
        "\n",
        "* Try datasets: `MNIST`, `CIFAR-10`, `IMDB  `, `Titanic`\n",
        "* Experiment with different hidden layers & neurons\n",
        "* Try different optimizers and learning rates\n",
        "* Apply regularization (`Dropout`, `L2`)\n",
        "* Explore pretrained models (`Transfer Learning`)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
