{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"  background: linear-gradient(145deg, #0f172a, #1e293b);  border: 4px solid transparent;  border-radius: 14px;  padding: 18px 22px;  margin: 12px 0;  font-size: 26px;  font-weight: 600;  color: #f8fafc;  box-shadow: 0 6px 14px rgba(0,0,0,0.25);  background-clip: padding-box;  position: relative;\">  <div style=\"    position: absolute;    inset: 0;    padding: 4px;    border-radius: 14px;    background: linear-gradient(90deg, #06b6d4, #3b82f6, #8b5cf6);    -webkit-mask:       linear-gradient(#fff 0 0) content-box,       linear-gradient(#fff 0 0);    -webkit-mask-composite: xor;    mask-composite: exclude;    pointer-events: none;  \"></div>    <b>Tensors, Layers, and Autoencoders</b>    <br/>  <span style=\"color:#9ca3af; font-size: 18px; font-weight: 400;\">(Introduction to Deep Learning with Keras)</span></div>\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "1. [Accessing Keras Layers and Tensors](#section-1)\n",
        "2. [Autoencoders: Architecture and Implementation](#section-2)\n",
        "3. [Introduction to Convolutional Neural Networks (CNNs)](#section-3)\n",
        "4. [Transfer Learning with ResNet50](#section-4)\n",
        "5. [Recurrent Neural Networks (RNNs) and LSTMs](#section-5)\n",
        "6. [Text Preprocessing and LSTM Implementation](#section-6)\n",
        "7. [Conclusion](#section-7)\n",
        "\n",
        "---\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 1. Accessing Keras Layers and Tensors</span><br>\n",
        "\n",
        "Deep learning models in Keras are composed of layers, and the data flows through these layers in the form of tensors. Understanding how to inspect these layers and define tensors is fundamental to debugging and building complex architectures.\n",
        "\n",
        "### Accessing Model Layers\n",
        "\n",
        "Once a model is defined, you can access its individual layers using the `.layers` attribute. This allows you to inspect the input shape, output shape, and the learnable weights (kernels and biases) of that specific layer.\n",
        "\n",
        "<div style=\"background: #e0f2fe; border-left: 16px solid #0284c7; padding: 14px 18px; border-radius: 8px; font-size: 18px; color: #075985;\"> ðŸ’¡ <b>Tip:</b> Layers in Keras are indexed. <code>model.layers[0]</code> refers to the first layer (often the input or first hidden layer), <code>model.layers[1]</code> the second, and so on. </div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "e:\\001_Github_Repo_all\\applied-deep-learning-keras\\.venv\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(np, \"object\"):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input Tensor: <KerasTensor shape=(None, 3), dtype=float32, sparse=False, ragged=False, name=keras_tensor>\n",
            "Output Tensor: <KerasTensor shape=(None, 2), dtype=float32, sparse=False, ragged=False, name=keras_tensor_1>\n",
            "Weights (Kernel & Bias):\n",
            "<Variable path=sequential/dense/kernel, shape=(3, 2), dtype=float32, value=[[ 0.21691716 -1.031103  ]\n",
            " [-0.22122705  0.4394809 ]\n",
            " [-0.8188      0.6998441 ]]>\n",
            "<Variable path=sequential/dense/bias, shape=(2,), dtype=float32, value=[0. 0.]>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "e:\\001_Github_Repo_all\\applied-deep-learning-keras\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import numpy as np\n",
        "\n",
        "# 1. Setup a dummy model for demonstration\n",
        "model = Sequential()\n",
        "model.add(Dense(2, input_shape=(3,), activation='relu'))  # Layer 0\n",
        "model.add(Dense(1))                                       # Layer 1\n",
        "model.build() # Build the model to initialize weights\n",
        "\n",
        "# 2. Accessing the first layer of a Keras model\n",
        "first_layer = model.layers[0]\n",
        "\n",
        "# 3. Printing the layer, and its input, output and weights\n",
        "print(\"Input Tensor:\", first_layer.input)\n",
        "print(\"Output Tensor:\", first_layer.output)\n",
        "print(\"Weights (Kernel & Bias):\")\n",
        "for weight in first_layer.weights:\n",
        "    print(weight)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### What are Tensors?\n",
        "\n",
        "Tensors are the primary data structure used in Deep Learning. They are multi-dimensional arrays.\n",
        "*   **Rank 2 Tensor**: A 2D array (Matrix). Shape: `(samples, features)`.\n",
        "*   **Rank 3 Tensor**: A 3D array (Cube). Shape: `(samples, time_steps, features)` or `(height, width, channels)`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rank 2 Tensor shape: (3, 3)\n",
            "Rank 3 Tensor shape: (3, 3, 3)\n"
          ]
        }
      ],
      "source": [
        "# Defining a rank 2 tensor (2 dimensions)\n",
        "T2 = [[1, 2, 3],\n",
        "      [4, 5, 6],\n",
        "      [7, 8, 9]]\n",
        "\n",
        "# Defining a rank 3 tensor (3 dimensions)\n",
        "T3 = [[1, 2, 3],\n",
        "      [4, 5, 6],\n",
        "      [7, 8, 9],\n",
        "      \n",
        "      [10, 11, 12],\n",
        "      [13, 14, 15],\n",
        "      [16, 17, 18],\n",
        "      \n",
        "      [19, 20, 21],\n",
        "      [22, 23, 24],\n",
        "      [25, 26, 27]]\n",
        "\n",
        "print(\"Rank 2 Tensor shape:\", np.array(T2).shape)\n",
        "print(\"Rank 3 Tensor shape:\", np.array(T3).reshape(3,3,3).shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Using Keras Backend to Inspect Intermediate Outputs\n",
        "\n",
        "Sometimes you need to see exactly what a specific layer is outputting for a given input. We can use the Keras backend (`K`) to create a function that maps the model inputs to a specific layer's output.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "module 'tensorflow.keras.backend' has no attribute 'function'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      5\u001b[39m out = model.layers[\u001b[32m0\u001b[39m].output\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Function that maps layer inputs to outputs\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# K.function([inputs], [outputs])\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m inp_to_out = \u001b[43mK\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m([inp], [out])\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Create dummy training data (1 sample, 3 features)\u001b[39;00m\n\u001b[32m     12\u001b[39m X_train = np.array([[\u001b[32m0.7\u001b[39m, \u001b[32m0.2\u001b[39m, \u001b[32m0.1\u001b[39m]])\n",
            "\u001b[31mAttributeError\u001b[39m: module 'tensorflow.keras.backend' has no attribute 'function'"
          ]
        }
      ],
      "source": [
        "import tensorflow.keras.backend as K\n",
        "\n",
        "# Get the input and output tensors of a model layer\n",
        "inp = model.layers[0].input\n",
        "out = model.layers[0].output\n",
        "\n",
        "# Function that maps layer inputs to outputs\n",
        "# K.function([inputs], [outputs])\n",
        "inp_to_out = K.function([inp], [out])\n",
        "\n",
        "# Create dummy training data (1 sample, 3 features)\n",
        "X_train = np.array([[0.7, 0.2, 0.1]])\n",
        "\n",
        "# We pass an input and get the output we'd get in that first layer\n",
        "layer_output = inp_to_out([X_train])\n",
        "\n",
        "print(\"Output of the first layer for X_train sample:\")\n",
        "print(layer_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "---\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 2. Autoencoders: Architecture and Implementation</span><br>\n",
        "\n",
        "### The Concept\n",
        "Autoencoders are a specific type of neural network architecture where the goal is to reconstruct the input.\n",
        "**INPUTS == OUTPUTS**\n",
        "\n",
        "The network compresses the input into a lower-dimensional representation (encoding) and then reconstructs it back to the original dimensions (decoding).\n",
        "\n",
        "### Use Cases\n",
        "\n",
        "| Use Case | Description |\n",
        "| :--- | :--- |\n",
        "| **Dimensionality Reduction** | Creating a smaller dimensional space representation of inputs (similar to PCA but non-linear). |\n",
        "| **De-noising Data** | If trained with clean data, the model learns to filter out irrelevant noise during reconstruction. |\n",
        "| **Anomaly Detection** | A poor reconstruction error implies the model has not seen this type of input before (anomaly). |\n",
        "\n",
        "### Building a Simple Autoencoder\n",
        "\n",
        "We will build a simple autoencoder that takes an input of size 100, compresses it to 4 neurons, and reconstructs it back to 100.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Instantiate a sequential model\n",
        "autoencoder = Sequential()\n",
        "\n",
        "# Add a hidden layer of 4 neurons (Bottleneck) and an input layer of 100\n",
        "# This compresses the 100 features down to 4\n",
        "autoencoder.add(Dense(4, input_shape=(100,), activation='relu'))\n",
        "\n",
        "# Add an output layer of 100 neurons\n",
        "# This attempts to reconstruct the original 100 features\n",
        "autoencoder.add(Dense(100, activation='sigmoid'))\n",
        "\n",
        "# Compile your model with the appropriate loss\n",
        "# Binary crossentropy is often used if inputs are normalized between 0 and 1\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "autoencoder.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Breaking it into an Encoder\n",
        "\n",
        "Once the autoencoder is trained, we often only care about the \"compressed\" representation (the encoding). We can build a separate model that consists only of the first layer of the autoencoder.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Building a separate model to encode inputs\n",
        "encoder = Sequential()\n",
        "\n",
        "# We add the FIRST layer of the trained autoencoder to this new model\n",
        "encoder.add(autoencoder.layers[0])\n",
        "\n",
        "# Create dummy test data (1 sample, 100 features)\n",
        "X_test = np.random.random((1, 100))\n",
        "\n",
        "# Predicting returns the four hidden layer neuron outputs\n",
        "encoded_data = encoder.predict(X_test)\n",
        "\n",
        "print(\"\\nEncoded representation (4 numbers):\")\n",
        "print(encoded_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "---\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 3. Introduction to Convolutional Neural Networks (CNNs)</span><br>\n",
        "\n",
        "CNNs are specialized neural networks for processing grid-like data, such as images.\n",
        "\n",
        "### Key Concepts\n",
        "1.  **Filters/Kernels**: Small matrices (e.g., 3x3) that slide over the input image to detect features (edges, textures).\n",
        "2.  **Feature Learning**: The network learns these filters automatically.\n",
        "3.  **Architecture**: Input -> Convolution + ReLU -> Pooling -> Flatten -> Fully Connected (Dense) -> Softmax.\n",
        "\n",
        "### Image Input Shape\n",
        "Images are Rank 3 tensors: `(Width, Height, Channels)`.\n",
        "*   Example: `(28, 28, 3)` for a color image (RGB).\n",
        "*   Example: `(28, 28, 1)` for a grayscale image.\n",
        "\n",
        "### Building a CNN in Keras\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten\n",
        "\n",
        "# Instantiate your model as usual\n",
        "model_cnn = Sequential()\n",
        "\n",
        "# Add a convolutional layer with 32 filters of size 3x3\n",
        "# input_shape=(28, 28, 1) implies a 28x28 grayscale image\n",
        "model_cnn.add(Conv2D(filters=32, \n",
        "                     kernel_size=3, \n",
        "                     input_shape=(28, 28, 1), \n",
        "                     activation='relu'))\n",
        "\n",
        "# Add another convolutional layer\n",
        "model_cnn.add(Conv2D(8, kernel_size=3, activation='relu'))\n",
        "\n",
        "# Flatten the output of the previous layer\n",
        "# This converts the 3D feature maps into a 1D vector for the Dense layer\n",
        "model_cnn.add(Flatten())\n",
        "\n",
        "# End this multiclass model with 3 outputs and softmax\n",
        "model_cnn.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model_cnn.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "---\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 4. Transfer Learning with ResNet50</span><br>\n",
        "\n",
        "ResNet50 is a powerful, deep convolutional network (50 layers) trained on the massive ImageNet dataset. Instead of training a model from scratch, we can use ResNet50 to classify images immediately.\n",
        "\n",
        "### Pre-processing Images\n",
        "ResNet50 expects images in a specific format and size (224x224).\n",
        "\n",
        "<div style=\"background: #e0f2fe; border-left: 16px solid #0284c7; padding: 14px 18px; border-radius: 8px; font-size: 18px; color: #075985;\"> ðŸ’¡ <b>Tip:</b> The code below requires an actual image file. Ensure you have an image path ready to replace <code>'path_to_your_image.jpg'</code>. </div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, ResNet50, decode_predictions\n",
        "\n",
        "# NOTE: Replace this with a valid path to an image on your system\n",
        "img_path = 'cheeseburger.jpg' \n",
        "\n",
        "# We will create a dummy image for demonstration purposes if file doesn't exist\n",
        "try:\n",
        "    # Load the image with the right target size for your model\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    \n",
        "    # Turn it into an array\n",
        "    img = image.img_to_array(img)\n",
        "    \n",
        "    # Expand the dimensions so that it's understood by our network:\n",
        "    # img.shape turns from (224, 224, 3) into (1, 224, 224, 3)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    \n",
        "    # Pre-process the img in the same way training images were\n",
        "    img = preprocess_input(img)\n",
        "    \n",
        "    print(\"Image pre-processed successfully. Shape:\", img.shape)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Could not load image (expected behavior if file missing). Error: {e}\")\n",
        "    # Create dummy random image for the next code block to run\n",
        "    img = np.random.randint(0, 255, (1, 224, 224, 3)).astype('float32')\n",
        "    img = preprocess_input(img)\n",
        "    print(\"Created dummy noise image for demonstration.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Using the Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instantiate a ResNet50 model with imagenet weights\n",
        "# This downloads the weights automatically\n",
        "model_resnet = ResNet50(weights='imagenet')\n",
        "\n",
        "# Predict with ResNet50 on our img\n",
        "preds = model_resnet.predict(img)\n",
        "\n",
        "# Decode predictions and print it\n",
        "# decode_predictions converts the probability array into readable class names\n",
        "print('Predicted:', decode_predictions(preds, top=1)[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "---\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 5. Recurrent Neural Networks (RNNs) and LSTMs</span><br>\n",
        "\n",
        "### What are RNNs?\n",
        "Standard neural networks assume inputs are independent. RNNs (Recurrent Neural Networks) are designed for sequential data (time series, text, audio). They have a \"memory\" where the output of a neuron is fed back into itself as input for the next step.\n",
        "\n",
        "### What are LSTMs?\n",
        "**Long Short-Term Memory (LSTM)** networks are a special kind of RNN capable of learning long-term dependencies. They solve the \"vanishing gradient\" problem of standard RNNs.\n",
        "\n",
        "**Internal Structure:**\n",
        "*   **Forget Gate**: Decides what information to throw away from the cell state.\n",
        "*   **Input Gate**: Decides which new information to store in the cell state.\n",
        "*   **Output Gate**: Decides what to output based on the cell state.\n",
        "\n",
        "### Use Cases for LSTMs\n",
        "*   Image captioning\n",
        "*   Speech to text\n",
        "*   Text translation\n",
        "*   Document summarization\n",
        "*   Text generation\n",
        "*   Musical composition\n",
        "\n",
        "---\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 6. Text Preprocessing and LSTM Implementation</span><br>\n",
        "\n",
        "To feed text into a neural network, we must convert words into numbers.\n",
        "\n",
        "### Manual Sequence Creation (Sliding Window)\n",
        "\n",
        "We want to predict the next word in a sequence. We can create training data by sliding a window over the text.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = 'Hi this is a small sentence'\n",
        "\n",
        "# We choose a sequence length\n",
        "seq_len = 3\n",
        "\n",
        "# Split text into a list of words\n",
        "words = text.split()\n",
        "print(\"Words:\", words)\n",
        "\n",
        "# Make lines\n",
        "lines = []\n",
        "for i in range(seq_len, len(words) + 1):\n",
        "    # Join the previous 3 words to form a sequence\n",
        "    line = ' '.join(words[i-seq_len:i])\n",
        "    lines.append(line)\n",
        "\n",
        "print(\"\\nGenerated Sequences:\")\n",
        "print(lines)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Tokenization\n",
        "We use the Keras `Tokenizer` to map words to integers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Instantiate Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "# Fit it on the previous lines\n",
        "tokenizer.fit_on_texts(lines)\n",
        "\n",
        "# Turn the lines into numeric sequences\n",
        "sequences = tokenizer.texts_to_sequences(lines)\n",
        "\n",
        "print(\"\\nNumeric Sequences:\")\n",
        "print(np.array(sequences))\n",
        "\n",
        "print(\"\\nWord Index Dictionary:\")\n",
        "print(tokenizer.index_word)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Building the LSTM Model\n",
        "\n",
        "We use an **Embedding Layer** to turn positive integers (indexes) into dense vectors of fixed size, followed by an LSTM layer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
        "\n",
        "model_lstm = Sequential()\n",
        "\n",
        "# Vocabulary size\n",
        "# +1 is required because index 0 is reserved for padding\n",
        "vocab_size = len(tokenizer.index_word) + 1\n",
        "\n",
        "# Starting with an embedding layer\n",
        "# input_dim: Size of vocabulary\n",
        "# output_dim: Dimension of the dense embedding\n",
        "# input_length: Length of input sequences\n",
        "model_lstm.add(Embedding(input_dim=vocab_size, output_dim=8, input_length=2)) \n",
        "# Note: input_length depends on how we structure X and y. \n",
        "# If we use the first 2 words to predict the 3rd, input_length is 2.\n",
        "\n",
        "# Adding an LSTM layer\n",
        "model_lstm.add(LSTM(8))\n",
        "\n",
        "# Adding a Dense hidden layer\n",
        "model_lstm.add(Dense(8, activation='relu'))\n",
        "\n",
        "# Adding an output layer with softmax\n",
        "# Output size is vocab_size because we are predicting one word out of the whole vocabulary\n",
        "model_lstm.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "model_lstm.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "---\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 7. Conclusion</span><br>\n",
        "\n",
        "### Summary of Learning\n",
        "In this notebook, we have covered the essential building blocks of Deep Learning using Keras:\n",
        "\n",
        "*   **Basics**: Understanding Tensors (Rank 2 vs Rank 3) and accessing model layers/weights.\n",
        "*   **Autoencoders**: Building architectures where Input = Output for dimensionality reduction and de-noising.\n",
        "*   **CNNs**: Using Convolutional layers (`Conv2D`) for image processing and feature extraction.\n",
        "*   **Transfer Learning**: Leveraging pre-trained models like **ResNet50** to classify images without training from scratch.\n",
        "*   **RNNs & LSTMs**: Handling sequential data (text) using Long Short-Term Memory networks.\n",
        "*   **Text Processing**: Using `Tokenizer` and `Embedding` layers to prepare text for Deep Learning models.\n",
        "\n",
        "### What's Next?\n",
        "To deepen your expertise, consider exploring the following topics:\n",
        "\n",
        "1.  **Deep Dive into CNNs**: Advanced architectures (Inception, VGG).\n",
        "2.  **Deep Dive into LSTMs**: Bidirectional LSTMs, GRUs.\n",
        "3.  **Keras Functional API**: For building complex models with non-linear topologies (shared layers, multiple inputs/outputs).\n",
        "4.  **GANs (Generative Adversarial Networks)**: For generating new data (images, art).\n",
        "5.  **Projects**: Apply these concepts to real-world datasets (Kaggle competitions, etc.).\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
