{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"  background: linear-gradient(145deg, #0f172a, #1e293b);  border: 4px solid transparent;  border-radius: 14px;  padding: 18px 22px;  margin: 12px 0;  font-size: 26px;  font-weight: 600;  color: #f8fafc;  box-shadow: 0 6px 14px rgba(0,0,0,0.25);  background-clip: padding-box;  position: relative;\">  <div style=\"    position: absolute;    inset: 0;    padding: 4px;    border-radius: 14px;    background: linear-gradient(90deg, #06b6d4, #3b82f6, #8b5cf6);    -webkit-mask:       linear-gradient(#fff 0 0) content-box,       linear-gradient(#fff 0 0);    -webkit-mask-composite: xor;    mask-composite: exclude;    pointer-events: none;  \"></div>    <b>Category Embeddings & Shared Layers</b>    <br/>  <span style=\"color:#9ca3af; font-size: 18px; font-weight: 400;\">(Advanced Deep Learning with Keras)</span></div>\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "1. [Category Embeddings: Overview](#section-1)\n",
        "2. [Defining Inputs](#section-2)\n",
        "3. [The Embedding Layer](#section-3)\n",
        "4. [Flattening the Output](#section-4)\n",
        "5. [Putting It All Together: The Embedding Model](#section-5)\n",
        "6. [Shared Layers: Concept](#section-6)\n",
        "7. [Implementing Shared Layers](#section-7)\n",
        "8. [Sharing Multiple Layers as a Model](#section-8)\n",
        "9. [Merge Layers: Overview](#section-9)\n",
        "10. [Implementing Merge Layers (Add)](#section-10)\n",
        "11. [Creating and Compiling Multi-Input Models](#section-11)\n",
        "12. [Fitting with Multiple Inputs](#section-12)\n",
        "13. [Predicting with Multiple Inputs](#section-13)\n",
        "14. [Evaluating with Multiple Inputs](#section-14)\n",
        "15. [Conclusion](#section-15)\n",
        "\n",
        "***\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 1. Category Embeddings: Overview</span><br>\n",
        "\n",
        "Category embeddings are a powerful technique in deep learning for handling categorical data (like team IDs, user IDs, or word indices). Instead of using one-hot encoding, which can result in massive sparse matrices, embeddings map integers to dense vectors of floating-point numbers.\n",
        "\n",
        "### Key Characteristics\n",
        "*   **Input**: Integers (representing categories).\n",
        "*   **Output**: Floats (dense vectors).\n",
        "*   **Dimensionality**: Embeddings increase dimensionality. The output layer often needs to be flattened back to 2D for subsequent dense layers.\n",
        "\n",
        "### Architecture Flow\n",
        "The typical flow for an embedding network is:\n",
        "`Input Layer (Integer)` $\\rightarrow$ `Embedding Layer (Lookup Table)` $\\rightarrow$ `Output Layer (Float)`\n",
        "\n",
        "<div style=\"background: #e0f2fe; border-left: 16px solid #0284c7; padding: 14px 18px; border-radius: 8px; font-size: 18px; color: #075985;\"> ðŸ’¡ <b>Tip:</b> Think of an embedding layer as a learnable lookup table where the network learns the best vector representation for each category during training. </div>\n",
        "\n",
        "***\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 2. Defining Inputs</span><br>\n",
        "\n",
        "The first step in building a Keras model using the Functional API is defining the input tensor. For embeddings, the input is typically a single integer per sample.\n",
        "\n",
        "### Code Implementation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "# Define the input tensor\n",
        "# shape=(1,) indicates a single integer input per sample\n",
        "input_tensor = Input(shape=(1,))\n",
        "\n",
        "print(input_tensor)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "***\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 3. The Embedding Layer</span><br>\n",
        "\n",
        "The `Embedding` layer is the core component. It requires specifying the size of the vocabulary (number of unique categories) and the dimensionality of the embedding vector.\n",
        "\n",
        "### Parameters\n",
        "*   `input_dim`: How many unique categories exist (e.g., number of teams).\n",
        "*   `input_length`: Length of the input sequence (1 in this case).\n",
        "*   `output_dim`: Size of the vector representing each category.\n",
        "\n",
        "### Code Implementation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "# Example: Total number of unique teams in the dataset\n",
        "n_teams = 10887\n",
        "\n",
        "# Create the embedding layer\n",
        "embed_layer = Embedding(input_dim=n_teams,\n",
        "                        input_length=1,\n",
        "                        output_dim=1,\n",
        "                        name='Team-Strength-Lookup')\n",
        "\n",
        "# Apply the embedding layer to the input tensor\n",
        "embed_tensor = embed_layer(input_tensor)\n",
        "\n",
        "print(embed_tensor)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "***\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 4. Flattening the Output</span><br>\n",
        "\n",
        "Embedding layers add a dimension. If you input a shape of `(Batch_Size, 1)`, the embedding layer outputs `(Batch_Size, 1, Output_Dim)`. To pass this to a standard Dense layer or output layer, we often need to flatten it back to 2D.\n",
        "\n",
        "### Code Implementation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Flatten\n",
        "\n",
        "# Flatten the embedding output\n",
        "# This converts shape (Batch, 1, 1) -> (Batch, 1)\n",
        "flatten_tensor = Flatten()(embed_tensor)\n",
        "\n",
        "print(flatten_tensor)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "***\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 5. Putting It All Together: The Embedding Model</span><br>\n",
        "\n",
        "We can now combine the Input, Embedding, and Flatten layers into a single Keras Model. This model takes an integer as input and outputs a float representing the \"strength\" or \"value\" of that category.\n",
        "\n",
        "### Code Implementation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# 1. Input Layer\n",
        "input_tensor = Input(shape=(1,))\n",
        "\n",
        "# 2. Define constants\n",
        "n_teams = 10887\n",
        "\n",
        "# 3. Embedding Layer\n",
        "embed_layer = Embedding(input_dim=n_teams,\n",
        "                        input_length=1,\n",
        "                        output_dim=1,\n",
        "                        name='Team-Strength-Lookup')\n",
        "\n",
        "# 4. Connect layers\n",
        "embed_tensor = embed_layer(input_tensor)\n",
        "flatten_tensor = Flatten()(embed_tensor)\n",
        "\n",
        "# 5. Create the Model\n",
        "model = Model(input_tensor, flatten_tensor)\n",
        "\n",
        "# Display model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "***\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 6. Shared Layers: Concept</span><br>\n",
        "\n",
        "Shared layers allow you to use the **same** layer instance (with the same weights) on multiple different inputs. This is useful when you have two inputs that are of the same type and should be processed in the exact same way (e.g., comparing two teams).\n",
        "\n",
        "### Key Features\n",
        "*   **Requirement**: Requires the Keras Functional API.\n",
        "*   **Flexibility**: Extremely flexible architecture design.\n",
        "*   **Mechanism**: The weights are shared because the *same object* is called on different tensors.\n",
        "\n",
        "***\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 7. Implementing Shared Layers</span><br>\n",
        "\n",
        "To share a layer, you instantiate it once, and then call that single instance on multiple input tensors.\n",
        "\n",
        "### Code Implementation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Define two separate inputs\n",
        "input_tensor_1 = Input((1,))\n",
        "input_tensor_2 = Input((1,))\n",
        "\n",
        "# Create a single shared layer instance\n",
        "# We do NOT create two Dense layers, just one.\n",
        "shared_layer = Dense(1)\n",
        "\n",
        "# Apply the SAME layer to both inputs\n",
        "output_tensor_1 = shared_layer(input_tensor_1)\n",
        "output_tensor_2 = shared_layer(input_tensor_2)\n",
        "\n",
        "print(\"Output 1:\", output_tensor_1)\n",
        "print(\"Output 2:\", output_tensor_2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "***\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 8. Sharing Multiple Layers as a Model</span><br>\n",
        "\n",
        "You can share entire models, not just single layers. Since a Keras `Model` acts like a layer, you can instantiate a model once and call it on multiple inputs. This allows complex preprocessing pipelines (like the embedding pipeline created in Section 5) to be shared.\n",
        "\n",
        "### Code Implementation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Step 1: Create the reusable model (from Section 5) ---\n",
        "input_tensor = Input(shape=(1,))\n",
        "n_teams = 10887\n",
        "embed_layer = Embedding(input_dim=n_teams,\n",
        "                        input_length=1,\n",
        "                        output_dim=1,\n",
        "                        name='Team-Strength-Lookup')\n",
        "embed_tensor = embed_layer(input_tensor)\n",
        "flatten_tensor = Flatten()(embed_tensor)\n",
        "\n",
        "# This model encapsulates the embedding and flattening logic\n",
        "model = Model(input_tensor, flatten_tensor)\n",
        "\n",
        "# --- Step 2: Use the model as a shared layer ---\n",
        "\n",
        "# Define two new inputs (e.g., Team A and Team B)\n",
        "input_tensor_1 = Input((1,))\n",
        "input_tensor_2 = Input((1,))\n",
        "\n",
        "# Pass both inputs through the SAME model\n",
        "output_tensor_1 = model(input_tensor_1)\n",
        "output_tensor_2 = model(input_tensor_2)\n",
        "\n",
        "print(\"Shared Model Output 1:\", output_tensor_1)\n",
        "print(\"Shared Model Output 2:\", output_tensor_2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "***\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 9. Merge Layers: Overview</span><br>\n",
        "\n",
        "When you have multiple inputs (like two teams competing), you eventually need to combine them to make a prediction. Keras provides **Merge Layers** for this purpose.\n",
        "\n",
        "### Common Merge Operations\n",
        "*   **Add**: Sums inputs element-wise.\n",
        "*   **Subtract**: Subtracts inputs element-wise.\n",
        "*   **Multiply**: Multiplies inputs element-wise.\n",
        "*   **Concatenate**: Joins tensors together along a specific axis.\n",
        "\n",
        "***\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 10. Implementing Merge Layers (Add)</span><br>\n",
        "\n",
        "The `Add` layer takes a **list** of tensors as input and returns a single tensor containing their sum.\n",
        "\n",
        "### Code Implementation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Add\n",
        "\n",
        "# Define inputs\n",
        "in_tensor_1 = Input((1,))\n",
        "in_tensor_2 = Input((1,))\n",
        "\n",
        "# Merge them using Add\n",
        "# Note: The input to Add() is a LIST of tensors\n",
        "out_tensor = Add()([in_tensor_1, in_tensor_2])\n",
        "\n",
        "print(\"Output Tensor (2 inputs):\", out_tensor)\n",
        "\n",
        "# Example with 3 inputs\n",
        "in_tensor_3 = Input((1,))\n",
        "out_tensor_3 = Add()([in_tensor_1, in_tensor_2, in_tensor_3])\n",
        "\n",
        "print(\"Output Tensor (3 inputs):\", out_tensor_3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "***\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 11. Creating and Compiling Multi-Input Models</span><br>\n",
        "\n",
        "To create a model with multiple inputs, you pass a **list** of input tensors to the `Model` constructor.\n",
        "\n",
        "### Code Implementation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define inputs\n",
        "in_tensor_1 = Input((1,))\n",
        "in_tensor_2 = Input((1,))\n",
        "\n",
        "# Merge logic\n",
        "out_tensor = Add()([in_tensor_1, in_tensor_2])\n",
        "\n",
        "# Create the model\n",
        "# inputs argument takes a list: [input_1, input_2]\n",
        "model = Model(inputs=[in_tensor_1, in_tensor_2], outputs=out_tensor)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "***\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 12. Fitting with Multiple Inputs</span><br>\n",
        "\n",
        "When fitting a model with multiple inputs, the `x` argument in `model.fit()` must be a list of numpy arrays (or tensors) that corresponds exactly to the list of input layers defined in the model.\n",
        "\n",
        "### Code Implementation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Generate dummy data\n",
        "# 10 samples, 1 feature each\n",
        "data_1 = np.random.randint(1, 100, size=(10, 1))\n",
        "data_2 = np.random.randint(1, 100, size=(10, 1))\n",
        "\n",
        "# Target: Simple sum for demonstration\n",
        "target = data_1 + data_2\n",
        "\n",
        "# Fit the model\n",
        "# Pass inputs as a list: [data_1, data_2]\n",
        "model.fit([data_1, data_2], target, epochs=1, verbose=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "***\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 13. Predicting with Multiple Inputs</span><br>\n",
        "\n",
        "Prediction follows the same pattern as fitting. You pass a list of numpy arrays to `model.predict()`.\n",
        "\n",
        "### Code Implementation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 1: 1 + 2 = 3\n",
        "# Note: Inputs must be 2D arrays (Batch Size, Features)\n",
        "pred_1 = model.predict([np.array([[1]]), np.array([[2]])])\n",
        "print(f\"Prediction for 1 + 2: {pred_1[0][0]}\")\n",
        "\n",
        "# Example 2: 42 + 119 = 161\n",
        "pred_2 = model.predict([np.array([[42]]), np.array([[119]])])\n",
        "print(f\"Prediction for 42 + 119: {pred_2[0][0]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "***\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 14. Evaluating with Multiple Inputs</span><br>\n",
        "\n",
        "Evaluation also requires the list format for inputs.\n",
        "\n",
        "### Code Implementation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "# Inputs: -1 and -2. Target: -3\n",
        "# Since the model learned addition, loss should be near 0\n",
        "loss = model.evaluate([np.array([[-1]]), np.array([[-2]])], \n",
        "                      np.array([[-3]]))\n",
        "\n",
        "print(f\"Evaluation Loss: {loss}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "***\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 15. Conclusion</span><br>\n",
        "\n",
        "In this notebook, we covered advanced Keras techniques for handling categorical data and complex architectures:\n",
        "\n",
        "1.  **Category Embeddings**: We learned how to transform integer inputs into dense float vectors using `Embedding` layers, which act as learnable lookup tables.\n",
        "2.  **Shared Layers**: We utilized the Functional API to apply the same layer (or even an entire model) to multiple inputs, allowing the network to learn shared representations.\n",
        "3.  **Merge Layers**: We explored how to combine multiple input streams using `Add` (and listed others like `Subtract`, `Multiply`, `Concatenate`).\n",
        "4.  **Multi-Input Workflow**: We demonstrated the syntax for `fit`, `predict`, and `evaluate` when working with models that require lists of inputs.\n",
        "\n",
        "**Next Steps**:\n",
        "*   Apply embeddings to real-world datasets like recommender systems.\n",
        "*   Experiment with `Concatenate` to combine embeddings with other numerical features.\n",
        "*   Use shared layers to build \"Siamese Networks\" for comparing similarity between inputs.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}