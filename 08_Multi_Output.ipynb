{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"  background: linear-gradient(145deg, #0f172a, #1e293b);  border: 4px solid transparent;  border-radius: 14px;  padding: 18px 22px;  margin: 12px 0;  font-size: 26px;  font-weight: 600;  color: #f8fafc;  box-shadow: 0 6px 14px rgba(0,0,0,0.25);  background-clip: padding-box;  position: relative;\">  <div style=\"    position: absolute;    inset: 0;    padding: 4px;    border-radius: 14px;    background: linear-gradient(90deg, #06b6d4, #3b82f6, #8b5cf6);    -webkit-mask:       linear-gradient(#fff 0 0) content-box,       linear-gradient(#fff 0 0);    -webkit-mask-composite: xor;    mask-composite: exclude;    pointer-events: none;  \"></div>    <b>Two-Output Models & Advanced Keras Architectures</b>    <br/>  <span style=\"color:#9ca3af; font-size: 18px; font-weight: 400;\">(Classification, Regression, and Skip Connections)</span></div>\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "1. [Simple Model with 2 Outputs](#section-1)\n",
        "2. [Fitting and Inspecting a 2-Output Model](#section-2)\n",
        "3. [Evaluating a 2-Output Model](#section-3)\n",
        "4. [Single Model for Classification and Regression](#section-4)\n",
        "5. [Compiling a Multi-Output Model](#section-5)\n",
        "6. [Fitting the Combination Model](#section-6)\n",
        "7. [Inspecting Weights and Manual Verification](#section-7)\n",
        "8. [Evaluating the Combination Model](#section-8)\n",
        "9. [Advanced Concepts: Wrap-up & Skip Connections](#section-9)\n",
        "10. [Conclusion](#section-10)\n",
        "\n",
        "***\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 1. Simple Model with 2 Outputs</span><br>\n",
        "\n",
        "In this section, we explore how to create a neural network using the Keras Functional API that takes a single input but produces two distinct outputs. This is useful when you want to predict two related variables simultaneously (e.g., the score of Team 1 and the score of Team 2).\n",
        "\n",
        "### Architecture\n",
        "The model consists of:\n",
        "1.  **Input Layer**: Accepts a tensor of shape `(1,)`.\n",
        "2.  **Output Layer**: A Dense layer with `2` units. This single layer produces two values.\n",
        "\n",
        "### Code Implementation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1. Define the Input\n",
        "input_tensor = Input(shape=(1,))\n",
        "\n",
        "# 2. Define the Output\n",
        "# We use a Dense layer with 2 units to predict 2 values (e.g., score_1 and score_2)\n",
        "output_tensor = Dense(2)(input_tensor)\n",
        "\n",
        "# 3. Build the Model\n",
        "model = Model(input_tensor, output_tensor)\n",
        "\n",
        "# 4. Compile the Model\n",
        "# We use 'mean_absolute_error' as the loss function for regression\n",
        "model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "\n",
        "print(\"Model compiled successfully.\")\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<div style=\"background: #e0f2fe; border-left: 16px solid #0284c7; padding: 14px 18px; border-radius: 8px; font-size: 18px; color: #075985;\"> ðŸ’¡ <b>Tip:</b> Even though there are two outputs, because they come from a single Dense layer, Keras treats this as a single tensor output of shape (batch_size, 2).</div>\n",
        "\n",
        "***\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 2. Fitting and Inspecting a 2-Output Model</span><br>\n",
        "\n",
        "To fit this model, our target variable `y` must match the shape of the output layer. Since the output layer has 2 units, `y` must have 2 columns.\n",
        "\n",
        "### Data Preview\n",
        "The dataset used represents tournament games. We use `seed_diff` as the input to predict both `score_1` and `score_2`.\n",
        "\n",
        "| | seed_diff | score_1 | score_2 |\n",
        "|---|---|---|---|\n",
        "| 0 | -3 | 41 | 50 |\n",
        "| 1 | 4 | 61 | 55 |\n",
        "| 2 | 5 | 59 | 63 |\n",
        "| 3 | 3 | 50 | 41 |\n",
        "| 4 | 1 | 54 | 63 |\n",
        "\n",
        "### Implementation: Fitting the Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating the sample data from the document\n",
        "data = {\n",
        "    'seed_diff': [-3, 4, 5, 3, 1],\n",
        "    'score_1': [41, 61, 59, 50, 54],\n",
        "    'score_2': [50, 55, 63, 41, 63]\n",
        "}\n",
        "games_tourney_train = pd.DataFrame(data)\n",
        "\n",
        "# Display the head\n",
        "print(games_tourney_train.head())\n",
        "\n",
        "# Prepare X and y\n",
        "X = games_tourney_train[['seed_diff']]\n",
        "y = games_tourney_train[['score_1', 'score_2']]\n",
        "\n",
        "# Fit the model\n",
        "# Note: We use a small number of epochs here for demonstration\n",
        "history = model.fit(X, y, epochs=100, verbose=0)\n",
        "print(\"Training complete.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Inspecting Model Weights\n",
        "After training, we can inspect the weights. Since we have 1 input and 2 outputs, the weight matrix will be shape `(1, 2)` and the bias vector will be shape `(2,)`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get weights\n",
        "weights = model.get_weights()\n",
        "\n",
        "print(\"Weights (Input -> Output):\")\n",
        "print(weights[0])\n",
        "print(\"\\nBiases:\")\n",
        "print(weights[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "***\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 3. Evaluating a 2-Output Model</span><br>\n",
        "\n",
        "Evaluation works similarly to fitting. We provide the test data `X` and the 2-column target `y`. The model returns a single scalar loss value representing the Mean Absolute Error averaged over both outputs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating synthetic test data for evaluation\n",
        "test_data = {\n",
        "    'seed_diff': [2, -1, 0],\n",
        "    'score_1': [55, 45, 50],\n",
        "    'score_2': [48, 52, 50]\n",
        "}\n",
        "games_tourney_test = pd.DataFrame(test_data)\n",
        "\n",
        "X_test = games_tourney_test[['seed_diff']]\n",
        "y_test = games_tourney_test[['score_1', 'score_2']]\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f\"\\nMean Absolute Error on Test Data: {loss}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "***\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 4. Single Model for Classification and Regression</span><br>\n",
        "\n",
        "We can build a model that performs **Regression** (predicting a number) and **Classification** (predicting a binary outcome) simultaneously.\n",
        "\n",
        "### Architecture Design\n",
        "1.  **Input**: `seed_diff`\n",
        "2.  **Regression Output**: Predicts the score difference (linear activation).\n",
        "3.  **Classification Output**: Predicts if Team 1 won (sigmoid activation).\n",
        "4.  **Connection**: In this specific example, the Classification output layer takes the **Regression Output** as its input. This creates a dependency chain.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "# 1. Input Layer\n",
        "input_tensor = Input(shape=(1,))\n",
        "\n",
        "# 2. Regression Output\n",
        "# Predicts a continuous value (e.g., score difference)\n",
        "output_tensor_reg = Dense(1, name='regression_output')(input_tensor)\n",
        "\n",
        "# 3. Classification Output\n",
        "# Takes the regression output as input!\n",
        "# Uses sigmoid to predict probability (0 to 1)\n",
        "output_tensor_class = Dense(1, activation='sigmoid', name='classification_output')(output_tensor_reg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "***\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 5. Compiling a Multi-Output Model</span><br>\n",
        "\n",
        "When a model has multiple output layers, we define the model by passing a **list** of outputs. We also compile it using a **list** of loss functions corresponding to each output.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Define the model with 1 input and 2 distinct output tensors\n",
        "model_combo = Model(input_tensor, [output_tensor_reg, output_tensor_class])\n",
        "\n",
        "# Compile the model\n",
        "# Loss 1 (Regression): Mean Absolute Error\n",
        "# Loss 2 (Classification): Binary Crossentropy\n",
        "model_combo.compile(\n",
        "    loss=['mean_absolute_error', 'binary_crossentropy'],\n",
        "    optimizer='adam'\n",
        ")\n",
        "\n",
        "model_combo.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<div style=\"background: #e0f2fe; border-left: 16px solid #0284c7; padding: 14px 18px; border-radius: 8px; font-size: 18px; color: #075985;\"> ðŸ’¡ <b>Tip:</b> The order of losses in the list must match the order of outputs defined in the `Model(inputs, [outputs])` list.</div>\n",
        "\n",
        "***\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 6. Fitting the Combination Model</span><br>\n",
        "\n",
        "To fit the model, we pass the input `X` and a **list** of targets `[y_reg, y_class]`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preparing data for the combined model\n",
        "# We need 'score_diff' (regression target) and 'won' (classification target)\n",
        "games_tourney_train['score_diff'] = games_tourney_train['score_1'] - games_tourney_train['score_2']\n",
        "games_tourney_train['won'] = (games_tourney_train['score_diff'] > 0).astype(int)\n",
        "\n",
        "X = games_tourney_train[['seed_diff']]\n",
        "y_reg = games_tourney_train[['score_diff']]\n",
        "y_class = games_tourney_train[['won']]\n",
        "\n",
        "# Fit the model\n",
        "# Notice y is a list: [regression_target, classification_target]\n",
        "history_combo = model_combo.fit(\n",
        "    X, \n",
        "    [y_reg, y_class], \n",
        "    epochs=100, \n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "print(\"Combined model training complete.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "***\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 7. Inspecting Weights and Manual Verification</span><br>\n",
        "\n",
        "We can inspect the weights to understand how the regression output feeds into the classification output.\n",
        "\n",
        "### Extracting Weights\n",
        "The model has two dense layers.\n",
        "1.  Layer 1: Input -> Regression Output\n",
        "2.  Layer 2: Regression Output -> Classification Output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "weights = model_combo.get_weights()\n",
        "\n",
        "print(\"Layer 1 Weights (Input -> Reg):\", weights[0])\n",
        "print(\"Layer 1 Bias:\", weights[1])\n",
        "print(\"Layer 2 Weights (Reg -> Class):\", weights[2])\n",
        "print(\"Layer 2 Bias:\", weights[3])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Manual Calculation Verification\n",
        "We can verify the model's prediction logic using the sigmoid function from `scipy`.\n",
        "\n",
        "$$ \\text{Sigmoid}(x) = \\frac{1}{1 + e^{-x}} $$\n",
        "\n",
        "The classification output is calculated as:\n",
        "$$ \\text{Class Output} = \\text{Sigmoid}(\\text{Reg Output} \\times W_2 + b_2) $$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.special import expit as sigmoid\n",
        "\n",
        "# Example values extracted from a hypothetical training run (or use current weights)\n",
        "# Let's use the actual trained weights from the code above\n",
        "w1 = weights[0][0][0]\n",
        "b1 = weights[1][0]\n",
        "w2 = weights[2][0][0]\n",
        "b2 = weights[3][0]\n",
        "\n",
        "# Assume an input value of 1.0\n",
        "input_val = 1.0\n",
        "\n",
        "# Calculate Regression Output\n",
        "reg_out = input_val * w1 + b1\n",
        "\n",
        "# Calculate Classification Output manually\n",
        "manual_class_out = sigmoid(reg_out * w2 + b2)\n",
        "\n",
        "print(f\"Input: {input_val}\")\n",
        "print(f\"Regression Output (Manual): {reg_out}\")\n",
        "print(f\"Classification Output (Manual): {manual_class_out}\")\n",
        "\n",
        "# Verify with Keras prediction\n",
        "keras_pred = model_combo.predict([input_val], verbose=0)\n",
        "print(f\"Keras Class Prediction: {keras_pred[1][0][0]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "***\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 8. Evaluating the Combination Model</span><br>\n",
        "\n",
        "When evaluating a multi-output model, Keras returns a list of metrics:\n",
        "1.  **Total Loss**: Sum of all losses.\n",
        "2.  **Loss 1**: Loss for the first output (Regression).\n",
        "3.  **Loss 2**: Loss for the second output (Classification).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare test data\n",
        "games_tourney_test['score_diff'] = games_tourney_test['score_1'] - games_tourney_test['score_2']\n",
        "games_tourney_test['won'] = (games_tourney_test['score_diff'] > 0).astype(int)\n",
        "\n",
        "X_test = games_tourney_test[['seed_diff']]\n",
        "y_reg_test = games_tourney_test[['score_diff']]\n",
        "y_class_test = games_tourney_test[['won']]\n",
        "\n",
        "# Evaluate\n",
        "evaluation = model_combo.evaluate(X_test, [y_reg_test, y_class_test])\n",
        "\n",
        "print(\"\\nEvaluation Results:\")\n",
        "print(f\"Total Loss: {evaluation[0]}\")\n",
        "print(f\"Regression Loss (MAE): {evaluation[1]}\")\n",
        "print(f\"Classification Loss (Binary Crossentropy): {evaluation[2]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "***\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 9. Advanced Concepts: Wrap-up & Skip Connections</span><br>\n",
        "\n",
        "### Course Summary\n",
        "Throughout this advanced Keras exploration, we have covered:\n",
        "*   **Functional API**: Building flexible graphs of layers.\n",
        "*   **Shared Layers**: Using the same layer instance multiple times (Siamese networks).\n",
        "*   **Categorical Embeddings**: Handling high-cardinality categorical data.\n",
        "*   **Multiple Inputs**: Merging text, images, and numerical data.\n",
        "*   **Multiple Outputs**: Predicting regression and classification targets simultaneously.\n",
        "\n",
        "### Skip Connections (Residual Connections)\n",
        "Skip connections are a powerful technique used in deep networks (like ResNet) to solve the vanishing gradient problem. They allow the model to \"skip\" layers and pass information directly deeper into the network.\n",
        "\n",
        "#### Implementation of Skip Connections\n",
        "In the example below, the `input_tensor` is concatenated with the `hidden_tensor` before the final output. This preserves the original input features alongside the learned features.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Concatenate\n",
        "\n",
        "# 1. Input\n",
        "input_tensor = Input((100,))\n",
        "\n",
        "# 2. Deep Hidden Layers\n",
        "hidden_tensor = Dense(256, activation='relu')(input_tensor)\n",
        "hidden_tensor = Dense(256, activation='relu')(hidden_tensor)\n",
        "hidden_tensor = Dense(256, activation='relu')(hidden_tensor)\n",
        "\n",
        "# 3. Skip Connection\n",
        "# Concatenate the original input with the processed hidden output\n",
        "output_tensor = Concatenate()([input_tensor, hidden_tensor])\n",
        "\n",
        "# 4. Final Output\n",
        "output_tensor = Dense(256, activation='relu')(output_tensor)\n",
        "\n",
        "# Build Model\n",
        "model_skip = Model(input_tensor, output_tensor)\n",
        "model_skip.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<div style=\"background: #e0f2fe; border-left: 16px solid #0284c7; padding: 14px 18px; border-radius: 8px; font-size: 18px; color: #075985;\"> ðŸ’¡ <b>Tip:</b> Skip connections smooth the loss landscape, making it easier for optimization algorithms (like Adam) to find the global minimum.</div>\n",
        "\n",
        "***\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ðŸ§¾ 10. Conclusion</span><br>\n",
        "\n",
        "In this notebook, we successfully transitioned from simple single-output models to complex multi-output architectures using the Keras Functional API.\n",
        "\n",
        "**Key Takeaways:**\n",
        "1.  **Flexibility**: The Functional API allows for non-linear topologies, shared layers, and multiple inputs/outputs.\n",
        "2.  **Multi-Task Learning**: We can train a single model to perform both regression and classification, potentially improving performance by learning shared representations.\n",
        "3.  **Evaluation**: Multi-output models return a list of losses, allowing granular analysis of model performance.\n",
        "4.  **Architecture Patterns**: Advanced patterns like Skip Connections are easily implemented using `Concatenate` or `Add` layers.\n",
        "\n",
        "**Next Steps:**\n",
        "*   Experiment with **Shared Layers** for comparing inputs (e.g., document similarity).\n",
        "*   Apply **Embeddings** to categorical inputs in multi-input models.\n",
        "*   Try implementing a **ResNet** block using the skip connection pattern demonstrated above.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}