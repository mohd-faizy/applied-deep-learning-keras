{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"  background: linear-gradient(145deg, #0f172a, #1e293b);  border: 4px solid transparent;  border-radius: 14px;  padding: 18px 22px;  margin: 12px 0;  font-size: 26px;  font-weight: 600;  color: #f8fafc;  box-shadow: 0 6px 14px rgba(0,0,0,0.25);  background-clip: padding-box;  position: relative;\">  <div style=\"    position: absolute;    inset: 0;    padding: 4px;    border-radius: 14px;    background: linear-gradient(90deg, #06b6d4, #3b82f6, #8b5cf6);    -webkit-mask:       linear-gradient(#fff 0 0) content-box,       linear-gradient(#fff 0 0);    -webkit-mask-composite: xor;    mask-composite: exclude;    pointer-events: none;  \"></div>    <b>INTRODUCTION TO DEEP LEARNING WITH KERAS</b>    <br/>  <span style=\"color:#9ca3af; font-size: 18px; font-weight: 400;\">(Based on the presentation by Miguel Esteban)</span></div>\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "1. [What is Keras?](#section-1)\n",
        "2. [Your First Neural Network](#section-2)\n",
        "3. [Surviving a Meteor Strike (The Workflow)](#section-3)\n",
        "4. [Conclusion](#conclusion)\n",
        "\n",
        "---\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ğŸ§¾ 1. WHAT IS KERAS?</span><br>\n",
        "\n",
        "### 1.1 Theano vs. Keras\n",
        "Before diving into Keras, it is important to understand the landscape of Deep Learning frameworks. Historically, frameworks like **Theano** were used, but they required low-level definitions of mathematical operations. **Keras** revolutionized this by providing a high-level API.\n",
        "\n",
        "Below is a comparison of the code required to build a simple training loop in Theano versus Keras.\n",
        "\n",
        "#### Theano (Low-Level, Verbose)\n",
        "*Note: Theano is largely obsolete now, but this illustrates the complexity Keras abstracts away.*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ad0f89b",
      "metadata": {},
      "source": [
        "```python\n",
        "# LEGACY CODE: For illustration of complexity only\n",
        "import theano\n",
        "import theano.tensor as T\n",
        "from theano.ifelse import ifelse\n",
        "import numpy as np\n",
        "from random import random\n",
        "\n",
        "# Define variables\n",
        "x = T.matrix('x')\n",
        "w1 = theano.shared(np.array([random(), random()]))\n",
        "w2 = theano.shared(np.array([random(), random()]))\n",
        "w3 = theano.shared(np.array([random(), random()]))\n",
        "\n",
        "# Define mathematical graph manually\n",
        "a2 = 1 / (1 + T.exp(-T.dot(x, w2) - b1))\n",
        "x2 = T.stack([a1, a2], axis=1)\n",
        "a3 = 1 / (1 + T.exp(-T.dot(x2, w3) - b2))\n",
        "\n",
        "# Define gradients and updates manually...\n",
        "# (Code continues for many lines)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "#### Keras (High-Level, Concise)\n",
        "Keras allows you to define the same logic in a fraction of the lines, focusing on layers rather than matrix multiplication math.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "e:\\001_Github_Repo_all\\applied-deep-learning-keras\\.venv\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(np, \"object\"):\n",
            "e:\\001_Github_Repo_all\\applied-deep-learning-keras\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Define model and add layers\n",
        "model = Sequential()\n",
        "model.add(Dense(2, input_shape=(2,), activation='sigmoid'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
        "\n",
        "# Train model (Conceptual inputs)\n",
        "# model.fit(inputs, outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 1.2 Key Features of Keras\n",
        "Keras is a Deep Learning framework written by **FranÃ§ois Chollet**. Its primary characteristics are:\n",
        "*   **Enables fast experimentation**: Go from idea to result with the least amount of delay.\n",
        "*   **Runs on top of other frameworks**: Historically Theano/CNTK, now primarily **TensorFlow**.\n",
        "*   **User-Friendly**: Designed for human beings, not machines.\n",
        "\n",
        "<div style=\"background: #e0f2fe; border-left: 16px solid #0284c7; padding: 14px 18px; border-radius: 8px; font-size: 18px; color: #075985;\"> ğŸ’¡ <b>Tip:</b> Keras is now the official high-level API of TensorFlow. While TensorFlow handles the low-level tensor operations, Keras provides the building blocks for models.</div>\n",
        "\n",
        "### 1.3 Why Use Keras?\n",
        "1.  **Fast industry-ready models**: widely used in production.\n",
        "2.  **For beginners and experts**: Easy to learn, deep enough to customize.\n",
        "3.  **Less code**: As seen in the comparison above.\n",
        "4.  **Build any architecture**: CNNs, RNNs, Transformers, etc.\n",
        "5.  **Deploy models in multiple platforms**: Mobile, Web, Embedded.\n",
        "\n",
        "### 1.4 Feature Engineering: ML vs. DL\n",
        "One of the biggest advantages of Deep Learning (DL) over traditional Machine Learning (ML) is how features are handled.\n",
        "\n",
        "| Approach | Process |\n",
        "| :--- | :--- |\n",
        "| **Machine Learning** | Input $\\rightarrow$ **Manual Feature Extraction** $\\rightarrow$ Classification $\\rightarrow$ Output |\n",
        "| **Deep Learning** | Input $\\rightarrow$ **Feature Extraction + Classification (Combined)** $\\rightarrow$ Output |\n",
        "\n",
        "In Deep Learning, the network learns the features itself (e.g., edges, shapes in images) without the human needing to manually define them.\n",
        "\n",
        "### 1.5 Unstructured Data\n",
        "Neural networks excel at handling **unstructured data**.\n",
        "*   **Structured Data**: Excel spreadsheets, SQL databases (Rows and Columns).\n",
        "*   **Unstructured Data**: Audio waves, Images, Video, Text.\n",
        "\n",
        "### 1.6 When to use Neural Networks?\n",
        "You should consider using Deep Learning/Neural Networks when:\n",
        "1.  You are dealing with **unstructured data** (e.g., Images of cats and dogs).\n",
        "2.  You **don't need easily interpretable results** (The \"Black Box\" problem is acceptable).\n",
        "3.  You can benefit from a **known architecture** (e.g., Convolutional Neural Networks for vision).\n",
        "\n",
        "---\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ğŸ§¾ 2. YOUR FIRST NEURAL NETWORK</span><br>\n",
        "\n",
        "### 2.1 Anatomy of a Neural Network\n",
        "A standard neural network consists of three main types of layers:\n",
        "1.  **Input Layer**: Receives the raw data.\n",
        "2.  **Hidden Layer(s)**: Where the computation and feature extraction happen.\n",
        "3.  **Output Layer**: Produces the final prediction.\n",
        "\n",
        "#### Parameters\n",
        "The network learns by adjusting parameters inside the neurons:\n",
        "*   **Weights ($w$)**: The strength of the connection between neurons.\n",
        "*   **Biases ($b$)**: An offset value allowing the activation function to shift.\n",
        "\n",
        "#### Gradient Descent\n",
        "The learning process involves minimizing a **Cost Function** ($J(w)$).\n",
        "*   Imagine a ball rolling down a valley.\n",
        "*   The bottom of the valley is the **Global Cost Minimum** ($J_{min}(w)$).\n",
        "*   **Gradient Descent** is the algorithm that calculates the slope (gradient) and updates the weights to move the \"ball\" closer to the minimum.\n",
        "\n",
        "### 2.2 The Sequential API\n",
        "The `Sequential` API in Keras is the easiest way to build a model. It allows you to stack layers linearly, one after the other.\n",
        "\n",
        "**Workflow:**\n",
        "1.  Initialize `Model`.\n",
        "2.  Add `Input Layer` / `Hidden Layer`.\n",
        "3.  Add `Hidden Layer` (Optional).\n",
        "4.  Add `Output Layer`.\n",
        "\n",
        "### 2.3 Defining the Network in Code\n",
        "Let's build a simple network with:\n",
        "*   Input shape of 3 features.\n",
        "*   One hidden layer with 2 neurons.\n",
        "*   One output layer with 1 neuron.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model structure defined.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# 1. Create a new sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# 2. Add an input and dense layer\n",
        "# Dense(2) = Layer with 2 neurons\n",
        "# input_shape=(3,) = Expecting 3 input features\n",
        "model.add(Dense(2, input_shape=(3,)))\n",
        "\n",
        "# 3. Add a final 1 neuron layer (Output)\n",
        "model.add(Dense(1))\n",
        "\n",
        "print(\"Model structure defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 2.4 Adding Activations\n",
        "Without activation functions, a neural network is just a linear regression model. Activations introduce non-linearity, allowing the network to learn complex patterns. A common activation function is **ReLU** (Rectified Linear Unit).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Re-defining the model with activation functions\n",
        "model = Sequential()\n",
        "\n",
        "# Add activation=\"relu\" to the hidden layer\n",
        "model.add(Dense(2, input_shape=(3,), activation=\"relu\"))\n",
        "\n",
        "# Output layer (Linear activation by default, suitable for regression)\n",
        "model.add(Dense(1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 2.5 Summarizing the Model\n",
        "Keras provides a powerful utility `model.summary()` to inspect the architecture and the number of parameters.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              â”‚             \u001b[38;5;34m8\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚             \u001b[38;5;34m3\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> (44.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11\u001b[0m (44.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> (44.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11\u001b[0m (44.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Display the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "#### Understanding the Parameters\n",
        "Let's break down the parameter count from the summary above:\n",
        "\n",
        "**Layer 1 (`dense_3`):**\n",
        "*   Inputs: 3\n",
        "*   Neurons: 2\n",
        "*   Weights: $3 \\times 2 = 6$\n",
        "*   Biases: $2$ (one per neuron)\n",
        "*   **Total**: $6 + 2 = 8$ parameters.\n",
        "\n",
        "**Layer 2 (`dense_4`):**\n",
        "*   Inputs: 2 (output from previous layer)\n",
        "*   Neurons: 1\n",
        "*   Weights: $2 \\times 1 = 2$\n",
        "*   Biases: $1$\n",
        "*   **Total**: $2 + 1 = 3$ parameters.\n",
        "\n",
        "**Total Trainable Parameters**: $8 + 3 = 11$.\n",
        "\n",
        "---\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ğŸ§¾ 3. SURVIVING A METEOR STRIKE (THE WORKFLOW)</span><br>\n",
        "\n",
        "### 3.1 The Problem Scenario\n",
        "Imagine a meteor is approaching Earth.\n",
        "*   **Data**: We have time ($t$) and position ($pos$) data.\n",
        "*   **Goal**: Predict the impact region (where position is at $t=0$).\n",
        "*   **Challenge**: We might have data for $t=-40$ to $t=-10$ and $t=+10$ to $t=+40$, but we need to interpolate the danger zone near $t=0$.\n",
        "\n",
        "This is a regression problem. We will simulate this data to make the code executable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training samples: 1600\n",
            "Testing samples: 400\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generating synthetic \"Meteor\" data (Parabolic trajectory)\n",
        "# y = x^2 + noise\n",
        "X = np.linspace(-40, 40, 2000)\n",
        "y = X**2 + np.random.normal(0, 50, 2000) # Adding some noise\n",
        "\n",
        "# Normalizing data for better neural network performance\n",
        "X_norm = X / 40.0\n",
        "y_norm = y / 1600.0\n",
        "\n",
        "# Split into train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_norm, y_norm, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training samples: {len(X_train)}\")\n",
        "print(f\"Testing samples: {len(X_test)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 3.2 Step 1: Define the Model (Recap)\n",
        "We define a model capable of learning non-linear relationships (the curve of the meteor).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Create model\n",
        "model = Sequential()\n",
        "\n",
        "# Hidden layer with more neurons to capture complexity\n",
        "model.add(Dense(50, input_shape=(1,), activation=\"relu\"))\n",
        "model.add(Dense(50, activation=\"relu\"))\n",
        "\n",
        "# Output layer (1 value: position)\n",
        "model.add(Dense(1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 3.3 Step 2: Compiling\n",
        "Before training, we must configure the learning process using `.compile()`.\n",
        "*   **Optimizer**: `adam` (Adaptive Moment Estimation) - a very efficient standard optimizer.\n",
        "*   **Loss Function**: `mse` (Mean Squared Error) - standard for regression problems.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model compiled.\n"
          ]
        }
      ],
      "source": [
        "# Compiling the model\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "print(\"Model compiled.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 3.4 Step 3: Training\n",
        "We train the model using `.fit()`. This is where the gradient descent happens.\n",
        "*   **Epochs**: One pass over the entire dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0249  \n",
            "Epoch 2/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0069\n",
            "Epoch 3/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0035\n",
            "Epoch 4/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022\n",
            "Epoch 5/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0016\n",
            "Epoch 6/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0013    \n",
            "Epoch 7/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0012    \n",
            "Epoch 8/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0012\n",
            "Epoch 9/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011\n",
            "Epoch 10/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011    \n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "# We use more epochs here to ensure convergence on the synthetic data\n",
        "history = model.fit(X_train, y_train, epochs=10, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 3.5 Step 4: Predicting\n",
        "Once trained, we can use the model to predict the position of the meteor at new time steps.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "First 5 predictions:\n",
            "[[0.7472998 ]\n",
            " [0.41110617]\n",
            " [0.10375381]\n",
            " [0.00769938]\n",
            " [0.0735693 ]]\n"
          ]
        }
      ],
      "source": [
        "# Predict on new data (Test set)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "# Look at the first 5 predictions\n",
        "print(\"First 5 predictions:\")\n",
        "print(preds[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 3.6 Step 5: Evaluating\n",
        "To check how well our model performs scientifically, we calculate the loss on data it hasn't seen before (the test set).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0010  \n",
            "Test Set Loss (MSE): 0.0010004951618611813\n"
          ]
        }
      ],
      "source": [
        "# Evaluate results\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Set Loss (MSE): {loss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<div style=\"background: #e0f2fe; border-left: 16px solid #0284c7; padding: 14px 18px; border-radius: 8px; font-size: 18px; color: #075985;\"> ğŸ’¡ <b>Tip:</b> In a real \"Meteor\" scenario, a low MSE implies our trajectory calculation is accurate, potentially saving the Earth by predicting the exact impact time and location!</div>\n",
        "\n",
        "---\n",
        "\n",
        "<br><span style=\"  display: inline-block;  color: #fff;  background: linear-gradient(135deg, #a31616ff, #02b7ffff);  padding: 12px 20px;  border-radius: 12px;  font-size: 28px;  font-weight: 700;  box-shadow: 0 4px 12px rgba(0,0,0,0.2);  transition: transform 0.2s ease, box-shadow 0.2s ease;\">  ğŸ§¾ 4. CONCLUSION</span><br>\n",
        "\n",
        "In this notebook, we covered the fundamentals of Deep Learning with Keras:\n",
        "\n",
        "1.  **Keras vs. Theano**: We saw how Keras simplifies the creation of neural networks, abstracting complex math into simple layers.\n",
        "2.  **Neural Network Architecture**: We learned about Input, Hidden, and Output layers, as well as Weights and Biases.\n",
        "3.  **The Keras Workflow**:\n",
        "    *   **Define**: `Sequential()`, `Dense()`.\n",
        "    *   **Compile**: `optimizer='adam'`, `loss='mse'`.\n",
        "    *   **Fit**: Training the model with data.\n",
        "    *   **Predict**: Generating outputs for new data.\n",
        "    *   **Evaluate**: Checking the model's accuracy.\n",
        "\n",
        "**Next Steps:**\n",
        "*   Experiment with changing the number of neurons or layers.\n",
        "*   Try different activation functions (e.g., `sigmoid`, `tanh`).\n",
        "*   Apply this workflow to a classification problem (e.g., classifying images instead of predicting numbers).\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
